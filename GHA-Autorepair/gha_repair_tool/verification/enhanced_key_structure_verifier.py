"""
ê°œì„ ëœ í‚¤ êµ¬ì¡° ê²€ì¦ ëª¨ë“ˆ (v3.0)

structural_verifier.mdì˜ ì² í•™ì— ë”°ë¥¸ ì²´ê³„ì  ê²€ì¦:
1. "í‚¤ êµ¬ì¡°" ê¸°ë°˜ ê²€ì¦ - ê°’ì€ ë¸”ë™ë°•ìŠ¤ë¡œ ì²˜ë¦¬
2. "ì•ˆì „í•œ ë³€ê²½" vs "ìœ„í—˜í•œ ë³€ê²½" ëª…í™•í•œ ë¶„ë¥˜  
3. Tier-1 ìŠ¤ë©œ ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ í—ˆìš©ëœ ë³€ê²½ ì²˜ë¦¬
4. steps ìˆœì„œ ë³€ê²½ ì—„ê²©í•œ ê²€ì¦
5. "ê°’ì´ ê³§ êµ¬ì¡°"ì¸ í‚¤ë“¤(needs, matrix)ì˜ ì—„ê²©í•œ ê²€ì¦
"""

import sys
from pathlib import Path
from pprint import pprint
from deepdiff import DeepDiff

try:
    from parser import GHAWorkflowParser
except ImportError:
    print("ERROR: 'parser.py'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
    sys.exit(1)

# ===== ê²€ì¦ ê·œì¹™ ì •ì˜ =====

# âœ… ì•ˆì „í•œ ë³€ê²½: ë‹¨ìˆœ ë©”íƒ€ë°ì´í„° ë° ë…¼ë¦¬ í‚¤ (ê°’ ë³€ê²½ ë¬´ì‹œ)
SAFE_METADATA_KEYS = {
    'name',      # UI í‘œì‹œìš© ì´ë¦„
    'env',       # í™˜ê²½ ë³€ìˆ˜
    'with',      # ì•¡ì…˜ ì…ë ¥ê°’
    'on',        # íŠ¸ë¦¬ê±° (ë…¼ë¦¬ì  ê²€ì¦ ëŒ€ìƒì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ)
    'if'         # ì¡°ê±´ (ë…¼ë¦¬ì  ê²€ì¦ ëŒ€ìƒì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œ)
}

# âœ… í—ˆìš©ëœ ìŠ¤ë©œ ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ í‚¤ ì¶”ê°€/ë³€ê²½
ALLOWED_SMELL_FIX_KEYS = {
    'permissions',      # Smell 15: ê¶Œí•œ ì„¤ì •
    'timeout-minutes',  # Smell 10: íƒ€ì„ì•„ì›ƒ ì„¤ì •
    'concurrency',      # Smell 4, 5: ë™ì‹œì„± ì œì–´
    'continue-on-error' # ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
}

# âœ… í—ˆìš©ëœ ìŠ¤ë©œ ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ íŠ¹ì • ê°’ ë³€ê²½ (ì¡°ê±´ë¶€)
ALLOWED_VALUE_CHANGE_CONTEXTS = {
    'uses',  # Smell 24: ë²„ì „ ì—…ê·¸ë ˆì´ë“œ (ì˜ˆ: @v2 â†’ @v4)
    'run'    # Smell 25: ì‚¬ìš© ì¤‘ë‹¨ëœ ëª…ë ¹ì–´ ìˆ˜ì • (ì˜ˆ: set-output â†’ GITHUB_OUTPUT)
}

# âŒ ìœ„í—˜í•œ ë³€ê²½: "ê°’ì´ ê³§ êµ¬ì¡°"ì¸ í‚¤ë“¤ (ì—„ê²©í•œ ê²€ì¦)
STRUCTURAL_VALUE_KEYS = {
    'needs',           # ì¡ ì˜ì¡´ì„± - ì‹¤í–‰ ìˆœì„œ ì •ì˜
    'strategy.matrix', # ë§¤íŠ¸ë¦­ìŠ¤ ì „ëµ - ì‹¤í–‰ ê°œìˆ˜/ì¡°í•© ì •ì˜
    'jobs',           # ì¡ ëª©ë¡ - ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì •ì˜
    'steps'           # ìŠ¤í… ëª©ë¡ - ì¡ ë‚´ ì‹¤í–‰ ìˆœì„œ ì •ì˜
}

# âŒ ìœ„í—˜í•œ ë³€ê²½: í•µì‹¬ êµ¬ì¡° ì‹ë³„ì (ì ˆëŒ€ ë³€ê²½ ë¶ˆê°€)
CORE_IDENTITY_KEYS = {
    'jobs.<job_id>',  # ì¡ ID ì´ë¦„
    'steps.id'        # ìŠ¤í… ID ì´ë¦„  
}


class EnhancedKeyStructureVerifier:
    """í–¥ìƒëœ í‚¤ êµ¬ì¡° ê²€ì¦ê¸° ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ê²€ì¦ê¸° ì´ˆê¸°í™”"""
        self.parser = GHAWorkflowParser()
        self.structural_verifier = StructuralValueVerifier()
    
    def verify_structural_safety(self, original_file, repaired_file):
        """êµ¬ì¡°ì  ì•ˆì „ì„± ê²€ì¦"""
        from pathlib import Path
        
        if isinstance(original_file, str):
            original_file = Path(original_file)
        if isinstance(repaired_file, str):
            repaired_file = Path(repaired_file)
            
        result = verify_enhanced_structural_equivalence(original_file, repaired_file)
        
        return {
            'is_safe': result['safe'],
            'issues': result['key_structure_issues'] + result.get('steps_issues', []) + result['structural_value_issues'],
            'details': result['details']
        }


class StructuralValueVerifier:
    """êµ¬ì¡°ì  ê°’ë“¤(needs, matrix ë“±)ì„ ê²€ì¦í•˜ëŠ” í´ë˜ìŠ¤"""
    
    @staticmethod
    def extract_structural_values(yaml_obj, path="root"):
        """YAMLì—ì„œ êµ¬ì¡°ì ìœ¼ë¡œ ì¤‘ìš”í•œ ê°’ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        structural_values = {}
        
        if isinstance(yaml_obj, dict):
            for key, value in yaml_obj.items():
                current_path = f"{path}.{key}"
                
                # needs í•„ë“œ ì²˜ë¦¬
                if key == "needs":
                    structural_values[current_path] = {
                        "type": "needs",
                        "value": value if isinstance(value, list) else [value] if value else []
                    }
                
                # matrix ì „ëµ ì²˜ë¦¬
                elif key == "matrix":
                    structural_values[current_path] = {
                        "type": "matrix",
                        "value": value
                    }
                
                # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ ê²€ìƒ‰
                if isinstance(value, (dict, list)):
                    child_values = StructuralValueVerifier.extract_structural_values(value, current_path)
                    structural_values.update(child_values)
        
        elif isinstance(yaml_obj, list):
            for i, item in enumerate(yaml_obj):
                current_path = f"{path}[{i}]"
                if isinstance(item, (dict, list)):
                    child_values = StructuralValueVerifier.extract_structural_values(item, current_path)
                    structural_values.update(child_values)
        
        return structural_values
    
    @staticmethod
    def compare_structural_values(orig_values, repaired_values):
        """êµ¬ì¡°ì  ê°’ë“¤ì„ ë¹„êµí•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ ì°¾ìŠµë‹ˆë‹¤."""
        issues = []
        
        # 1. êµ¬ì¡°ì  ê°’ì´ ì œê±°ëœ ê²½ìš°
        removed_paths = set(orig_values.keys()) - set(repaired_values.keys())
        for path in removed_paths:
            value_type = orig_values[path]["type"]
            issues.append(f"êµ¬ì¡°ì  ê°’ ì œê±°: {path} (íƒ€ì…: {value_type})")
        
        # 2. êµ¬ì¡°ì  ê°’ì´ ì¶”ê°€ëœ ê²½ìš° (ì¼ë¶€ëŠ” í—ˆìš©)
        added_paths = set(repaired_values.keys()) - set(orig_values.keys())
        for path in added_paths:
            value_type = repaired_values[path]["type"]
            if not StructuralValueVerifier._is_allowed_structural_addition(path, value_type):
                issues.append(f"ì˜ˆìƒì¹˜ ëª»í•œ êµ¬ì¡°ì  ê°’ ì¶”ê°€: {path} (íƒ€ì…: {value_type})")
        
        # 3. ê³µí†µ êµ¬ì¡°ì  ê°’ë“¤ì˜ ë³€ê²½ ê²€ì‚¬
        common_paths = set(orig_values.keys()) & set(repaired_values.keys())
        for path in common_paths:
            orig_info = orig_values[path]
            repaired_info = repaired_values[path]
            
            # needs ì˜ì¡´ì„± ë³€ê²½ ê²€ì‚¬
            if orig_info["type"] == "needs":
                orig_deps = set(orig_info["value"])
                repaired_deps = set(repaired_info["value"])
                
                if orig_deps != repaired_deps:
                    issues.append(f"needs ì˜ì¡´ì„± ë³€ê²½: {path} ({orig_deps} â†’ {repaired_deps})")
            
            # matrix ì „ëµ ë³€ê²½ ê²€ì‚¬
            elif orig_info["type"] == "matrix":
                if orig_info["value"] != repaired_info["value"]:
                    issues.append(f"matrix ì „ëµ ë³€ê²½: {path}")
        
        return issues
    
    @staticmethod
    def _is_allowed_structural_addition(path, value_type):
        """êµ¬ì¡°ì  ê°’ ì¶”ê°€ê°€ í—ˆìš©ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        # needsì™€ matrixëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¶”ê°€ë˜ë©´ ì•ˆ ë¨
        # ë‹¨, smell ìˆ˜ì • ê´€ë ¨ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ëŠ” í—ˆìš© ê°€ëŠ¥
        return False


def verify_enhanced_structural_equivalence(original_file: Path, repaired_file: Path):
    """
    í–¥ìƒëœ êµ¬ì¡°ì  ë™ì¹˜ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    í‚¤ êµ¬ì¡° + êµ¬ì¡°ì  ê°’ ëª¨ë‘ ê²€ì¦
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼ ìƒì„¸ ì •ë³´
    """
    print("="*70)
    print(f"ğŸ”¬ Enhanced êµ¬ì¡° ê²€ì¦ - ì›ë³¸: {original_file.name}")
    print(f"ğŸ”¬ Enhanced êµ¬ì¡° ê²€ì¦ - ìˆ˜ì •: {repaired_file.name}")
    print("="*70)

    # 1. íŒŒì‹±
    parser = GHAWorkflowParser()
    ast_orig = parser.parse(original_file)
    ast_repaired = parser.parse(repaired_file)

    if not ast_orig or not ast_repaired:
        print("ERROR: íŒŒì¼ íŒŒì‹±ì— ì‹¤íŒ¨í•˜ì—¬ ê²€ì¦ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.", file=sys.stderr)
        return {"safe": False, "reason": "parsing_failed"}

    # 2. í‚¤ êµ¬ì¡° ê²€ì¦ (ê¸°ì¡´ ë¡œì§)
    orig_key_structure = _extract_key_structure(ast_orig)
    repaired_key_structure = _extract_key_structure(ast_repaired)
    key_structure_issues = _compare_key_structures(orig_key_structure, repaired_key_structure)
    
    # 3. Steps ìˆœì„œ ê²€ì¦ (íŠ¹ë³„ ì²˜ë¦¬)
    steps_issues = _check_steps_order_changes(ast_orig, ast_repaired)
    
    # 4. êµ¬ì¡°ì  ê°’ ê²€ì¦ (ìƒˆë¡œìš´ ë¡œì§)
    verifier = StructuralValueVerifier()
    orig_structural_values = verifier.extract_structural_values(ast_orig)
    repaired_structural_values = verifier.extract_structural_values(ast_repaired)
    structural_value_issues = verifier.compare_structural_values(orig_structural_values, repaired_structural_values)
    
    # 5. ê²°ê³¼ í†µí•©
    print("\\n[1] í‚¤ êµ¬ì¡° ê²€ì¦ ê²°ê³¼:")
    print("-" * 40)
    if key_structure_issues:
        print("âŒ í‚¤ êµ¬ì¡° ë¬¸ì œ ë°œê²¬:")
        for issue in key_structure_issues:
            print(f"  - {issue}")
    else:
        print("âœ… í‚¤ êµ¬ì¡° ì•ˆì „")
    
    print("\\n[2] Steps ìˆœì„œ ê²€ì¦ ê²°ê³¼:")
    print("-" * 40)
    if steps_issues:
        print("âŒ Steps ìˆœì„œ ë¬¸ì œ ë°œê²¬:")
        for issue in steps_issues:
            print(f"  - {issue}")
    else:
        print("âœ… Steps ìˆœì„œ ì•ˆì „")
    
    print("\\n[3] êµ¬ì¡°ì  ê°’ ê²€ì¦ ê²°ê³¼:")
    print("-" * 40)
    if structural_value_issues:
        print("âŒ êµ¬ì¡°ì  ê°’ ë¬¸ì œ ë°œê²¬:")
        for issue in structural_value_issues:
            print(f"  - {issue}")
    else:
        print("âœ… êµ¬ì¡°ì  ê°’ ì•ˆì „")
    
    # 6. ìµœì¢… íŒì •
    all_issues = key_structure_issues + steps_issues + structural_value_issues
    is_safe = len(all_issues) == 0
    
    print("\\n[4] ìµœì¢… íŒì •:")
    print("-" * 40)
    if is_safe:
        print("ğŸ‰ êµ¬ì¡°ì ìœ¼ë¡œ ì•ˆì „í•¨")
    else:
        print(f"âš ï¸  êµ¬ì¡°ì  ìœ„í—˜ ({len(all_issues)}ê°œ ë¬¸ì œ)")
    
    return {
        "safe": is_safe,
        "key_structure_issues": key_structure_issues,
        "steps_issues": steps_issues,
        "structural_value_issues": structural_value_issues,
        "total_issues": len(all_issues),
        "details": {
            "original_structural_values": orig_structural_values,
            "repaired_structural_values": repaired_structural_values
        }
    }


def _check_steps_order_changes(ast_orig, ast_repaired):
    """Steps ìˆœì„œ ë³€ê²½ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    issues = []
    
    # ëª¨ë“  jobsë¥¼ ìˆœíšŒí•˜ë©´ì„œ steps í™•ì¸
    orig_jobs = ast_orig.get('jobs', {})
    repaired_jobs = ast_repaired.get('jobs', {})
    
    # ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” jobë“¤ë§Œ í™•ì¸
    common_jobs = set(orig_jobs.keys()) & set(repaired_jobs.keys())
    
    for job_name in common_jobs:
        orig_steps = orig_jobs[job_name].get('steps', [])
        repaired_steps = repaired_jobs[job_name].get('steps', [])
        
        # steps ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ì´ë¯¸ ë‹¤ë¥¸ ê²€ì¦ì—ì„œ ì¡í ê²ƒ
        if len(orig_steps) != len(repaired_steps):
            continue
        
        # Steps ìˆœì„œ ë³€ê²½ vs ê°’ ë³€ê²½ êµ¬ë³„
        if _is_steps_reordered(orig_steps, repaired_steps):
            issues.append(f"Steps ìˆœì„œ ë³€ê²½ ê°ì§€: jobs.{job_name}.steps")
    
    return issues


def _is_steps_reordered(orig_steps, repaired_steps):
    """
    Steps ìˆœì„œ ê²€ì¦ ìƒì„¸ ë¡œì§ (structural_verifier.md 5ë²ˆ í•­ëª©)
    
    steps ë¦¬ìŠ¤íŠ¸ì˜ ìˆœì„œ ë³€ê²½ì€ ì¹˜ëª…ì ì¸ êµ¬ì¡° ë³€ê²½ì´ë¯€ë¡œ 
    "ì§€ë¬¸(Fingerprint)" ë¹„êµë¥¼ í†µí•´ ì—„ê²©í•˜ê²Œ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Returns:
        bool: True if steps are reordered (UNSAFE), False if safe
    """
    # 1. ê¸¸ì´ í™•ì¸ (ë‹¤ë¥´ë©´ UNSAFE)
    if len(orig_steps) != len(repaired_steps):
        return True
    
    # 2. ê° ìŠ¤í…ì˜ "í•µì‹¬ ì§€ë¬¸" ë¹„êµ
    for i, (orig_step, repaired_step) in enumerate(zip(orig_steps, repaired_steps)):
        orig_fingerprint = _extract_step_fingerprint(orig_step)
        repaired_fingerprint = _extract_step_fingerprint(repaired_step)
        
        # 3. ê°™ì€ ìœ„ì¹˜(index)ì˜ ìŠ¤í…ì´ ë‹¤ë¥¸ ì§€ë¬¸ì„ ê°€ì§€ë©´ UNSAFE
        if not _is_fingerprint_compatible(orig_fingerprint, repaired_fingerprint):
            return True
    
    # 4. ëª¨ë“  ìŠ¤í…ì˜ ì§€ë¬¸ì´ ìˆœì„œëŒ€ë¡œ ì¼ì¹˜í•˜ë©´ SAFE
    return False


def _normalize_whitespace(text):
    """
    í…ìŠ¤íŠ¸ì˜ ì¤„ë°”ê¿ˆê³¼ ê³µë°±ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    í–¥ìƒëœ ê²€ì¦ì—ì„œ ì˜ë¯¸ ì—†ëŠ” í¬ë§·íŒ… ì°¨ì´ëŠ” ë¬´ì‹œí•˜ë„ë¡ í•©ë‹ˆë‹¤:
    - ì¤„ ë ê³µë°± ì œê±°
    - ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì •ê·œí™”
    - ë§ˆì§€ë§‰ ì¤„ë°”ê¿ˆ í†µì¼
    """
    if not isinstance(text, str):
        return text
    
    # 1. ê° ì¤„ì˜ ë ê³µë°± ì œê±°
    lines = text.splitlines()
    lines = [line.rstrip() for line in lines]
    
    # 2. ë¹ˆ ì¤„ë“¤ ì •ë¦¬ (ì—°ì†ëœ ë¹ˆ ì¤„ì€ í•˜ë‚˜ë¡œ)
    normalized_lines = []
    prev_empty = False
    for line in lines:
        if line.strip() == '':
            if not prev_empty:
                normalized_lines.append('')
            prev_empty = True
        else:
            normalized_lines.append(line)
            prev_empty = False
    
    # 3. ë§ˆì§€ë§‰ ë¹ˆ ì¤„ ì œê±°
    while normalized_lines and normalized_lines[-1] == '':
        normalized_lines.pop()
    
    return '\n'.join(normalized_lines)


def _remove_comments(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì„ ë¼ì¸ì„ ì œê±°í•©ë‹ˆë‹¤.
    
    Shell/Bash ìŠ¤íƒ€ì¼ì˜ ì£¼ì„ (#ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)ì„ ì œê±°í•˜ì—¬
    ì£¼ì„ë§Œ ë‹¤ë¥¸ ê²½ìš°ë¥¼ í—ˆìš©ëœ ë³€ê²½ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    if not isinstance(text, str):
        return text
    
    lines = text.splitlines()
    non_comment_lines = []
    
    for line in lines:
        stripped_line = line.strip()
        # ì™„ì „íˆ ì£¼ì„ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ë¼ì¸ì€ ì œê±°
        if stripped_line.startswith('#') or stripped_line == '':
            continue
        # ë¼ì¸ ëì˜ ì£¼ì„ì€ ì œê±° (ë‹¨ìˆœ êµ¬í˜„)
        if '#' in line:
            # ë¬¸ìì—´ ì•ˆì˜ #ì€ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ë‹¨ìˆœ êµ¬í˜„
            # ì‹¤ì œ ëª…ë ¹ì–´ì—ì„œ #ì´ í¬í•¨ëœ ê²½ìš°ëŠ” ë“œë¬¼ê¸° ë•Œë¬¸
            comment_pos = line.find('#')
            line_without_comment = line[:comment_pos].rstrip()
            if line_without_comment:
                non_comment_lines.append(line_without_comment)
        else:
            non_comment_lines.append(line)
    
    return '\n'.join(non_comment_lines)


def _extract_step_fingerprint(step):
    """
    ê° ìŠ¤í…ì˜ í•µì‹¬ ì§€ë¬¸ ì¶”ì¶œ
    
    í•µì‹¬ ì§€ë¬¸: uses í‚¤ì˜ ê°’ ë˜ëŠ” run í‚¤ì˜ ê°’
    (name ë“± ë‹¤ë¥¸ í‚¤ì˜ ë³€ê²½ì€ ë¬´ì‹œ)
    """
    if 'uses' in step:
        # uses stepì˜ ê²½ìš°: action ì´ë¦„ (ë²„ì „ ì œì™¸ ê°€ëŠ¥)
        uses_value = step['uses']
        # ë²„ì „ ì—…ê·¸ë ˆì´ë“œëŠ” í—ˆìš©ëœ ë³€ê²½ì´ë¯€ë¡œ ê¸°ë³¸ action ì´ë¦„ë§Œ ì¶”ì¶œ
        action_name = uses_value.split('@')[0] if '@' in uses_value else uses_value
        return {'type': 'uses', 'action': action_name, 'full_uses': uses_value}
    
    elif 'run' in step:
        # run stepì˜ ê²½ìš°: run ëª…ë ¹ì–´ ë‚´ìš© (ì¤„ë°”ê¿ˆ ì •ê·œí™” ì ìš©)
        normalized_command = _normalize_whitespace(step['run'])
        return {'type': 'run', 'command': normalized_command}
    
    else:
        # ê¸°íƒ€ step: í‚¤ êµ¬ì¡°ë¡œ ì‹ë³„
        keys = set(step.keys()) - SAFE_METADATA_KEYS - ALLOWED_SMELL_FIX_KEYS
        return {'type': 'other', 'keys': frozenset(keys)}


def _is_fingerprint_compatible(orig_fp, repaired_fp):
    """
    ë‘ ìŠ¤í…ì˜ ì§€ë¬¸ì´ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸
    
    í—ˆìš©ë˜ëŠ” ë³€ê²½:
    - uses: ë²„ì „ ì—…ê·¸ë ˆì´ë“œ (Smell 24)
    - run: ì‚¬ìš© ì¤‘ë‹¨ëœ ëª…ë ¹ì–´ ìˆ˜ì • (Smell 25)
    """
    # íƒ€ì…ì´ ë‹¤ë¥´ë©´ í˜¸í™˜ë˜ì§€ ì•ŠìŒ
    if orig_fp['type'] != repaired_fp['type']:
        return False
    
    if orig_fp['type'] == 'uses':
        # uses step: action ì´ë¦„ì´ ê°™ìœ¼ë©´ í˜¸í™˜ (ë²„ì „ ì—…ê·¸ë ˆì´ë“œ í—ˆìš©)
        if orig_fp['action'] == repaired_fp['action']:
            return True
        # action ì´ë¦„ì´ ë‹¤ë¥´ë©´ í˜¸í™˜ë˜ì§€ ì•ŠìŒ
        return False
    
    elif orig_fp['type'] == 'run':
        # run step: ëª…ë ¹ì–´ ë‚´ìš©ì´ ê°™ìœ¼ë©´ í˜¸í™˜
        if orig_fp['command'] == repaired_fp['command']:
            return True
        # TODO: Smell 25 (ì‚¬ìš© ì¤‘ë‹¨ëœ ëª…ë ¹ì–´ ìˆ˜ì •) ê²€ì¦ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
        # ì˜ˆ: set-output â†’ GITHUB_OUTPUT ë³€ê²½ì€ í—ˆìš©
        return _is_allowed_run_command_change(orig_fp['command'], repaired_fp['command'])
    
    else:
        # ê¸°íƒ€ step: í‚¤ êµ¬ì¡°ê°€ ê°™ìœ¼ë©´ í˜¸í™˜
        return orig_fp['keys'] == repaired_fp['keys']


def _is_allowed_run_command_change(orig_command, repaired_command):
    """
    í—ˆìš©ëœ run ëª…ë ¹ì–´ ë³€ê²½ì¸ì§€ í™•ì¸ (Smell 25 + ì£¼ì„ ì œê±°)
    
    í—ˆìš©ë˜ëŠ” ë³€ê²½:
    - set-output â†’ GITHUB_OUTPUT ë“±ì˜ ì‚¬ìš© ì¤‘ë‹¨ëœ ëª…ë ¹ì–´ ìˆ˜ì •
    - ì£¼ì„ ì œê±° (# ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸)
    - ì¤„ë°”ê¿ˆ ë° ê³µë°± ì •ê·œí™”
    """
    # 1. ì¤„ë°”ê¿ˆ ì •ê·œí™” í›„ ë™ì¼í•œì§€ í™•ì¸
    normalized_orig = _normalize_whitespace(orig_command)
    normalized_repaired = _normalize_whitespace(repaired_command)
    
    if normalized_orig == normalized_repaired:
        return True  # ì¤„ë°”ê¿ˆ ì°¨ì´ë§Œ ìˆëŠ” ê²½ìš° í—ˆìš©
    
    # 2. ì£¼ì„ ì œê±° í™•ì¸
    orig_without_comments = _remove_comments(normalized_orig)
    repaired_without_comments = _remove_comments(normalized_repaired)
    
    if orig_without_comments == repaired_without_comments:
        return True  # ì£¼ì„ë§Œ ì œê±°ëœ ê²½ìš° í—ˆìš©
    
    # 3. deprecated command patterns í™•ì¸
    deprecated_patterns = [
        ('set-output', 'GITHUB_OUTPUT'),
        ('add-path', 'GITHUB_PATH'),
        ('::set-env', 'GITHUB_ENV')
    ]
    
    # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¶„ì„ í•„ìš”)
    for old_pattern, new_pattern in deprecated_patterns:
        if old_pattern in normalized_orig and new_pattern in normalized_repaired:
            return True
    
    return False
    orig_identities = _extract_step_identities(orig_steps)
    repaired_identities = _extract_step_identities(repaired_steps)
    
    # ê°™ì€ stepë“¤ì´ ë‹¤ë¥¸ ìˆœì„œë¡œ ë‚˜íƒ€ë‚˜ë©´ ìˆœì„œ ë³€ê²½
    if set(orig_identities) == set(repaired_identities) and orig_identities != repaired_identities:
        return True
    
    return False


def _extract_step_identities(steps):
    """ê° stepì˜ ìµœì†Œí•œì˜ ì‹ë³„ ì •ë³´ ì¶”ì¶œ"""
    identities = []
    
    for step in steps:
        # Step íƒ€ì… ê²°ì •: uses vs run vs name ê¸°ë°˜ ì‹ë³„
        if 'uses' in step:
            # uses stepì€ action ì´ë¦„ì˜ prefixë§Œ ì‚¬ìš© (ë²„ì „ ì œì™¸)
            uses_value = step['uses']
            action_name = uses_value.split('@')[0] if '@' in uses_value else uses_value
            identity = f"uses:{action_name}"
        elif 'run' in step:
            # run stepì€ nameì´ ìˆìœ¼ë©´ name, ì—†ìœ¼ë©´ runì˜ ì²« ë‹¨ì–´
            if 'name' in step:
                identity = f"run:{step['name']}"
            else:
                run_first_word = step['run'].split()[0] if step['run'].strip() else "run"
                identity = f"run:{run_first_word}"
        else:
            # ê¸°íƒ€ stepì€ í‚¤ ì¡°í•© ì‚¬ìš©
            identity = f"other:{'-'.join(sorted(step.keys()))}"
        
        identities.append(identity)
    
    return identities


def _extract_key_structure(yaml_obj, path="root"):
    """
    YAML ê°ì²´ì—ì„œ í‚¤ êµ¬ì¡°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ê°’ì€ ë¸”ë™ë°•ìŠ¤ë¡œ ì²˜ë¦¬í•˜ê³  íƒ€ì… ì •ë³´ë§Œ ê¸°ë¡í•©ë‹ˆë‹¤.
    """
    structure = {}
    
    if isinstance(yaml_obj, dict):
        structure[path] = {
            "type": "dict",
            "keys": list(yaml_obj.keys())
        }
        
        for key, value in yaml_obj.items():
            child_path = f"{path}.{key}"
            child_structure = _extract_key_structure(value, child_path)
            structure.update(child_structure)
    
    elif isinstance(yaml_obj, list):
        structure[path] = {
            "type": "list",
            "length": len(yaml_obj)
        }
        
        for i, item in enumerate(yaml_obj):
            child_path = f"{path}[{i}]"
            child_structure = _extract_key_structure(item, child_path)
            structure.update(child_structure)
    
    else:
        # ê°’ì€ ë¸”ë™ë°•ìŠ¤ë¡œ ì²˜ë¦¬ - íƒ€ì…ë§Œ ê¸°ë¡
        structure[path] = {
            "type": "value",
            "value_type": type(yaml_obj).__name__
        }
    
    return structure


def _compare_key_structures(orig_structure, repaired_structure):
    """
    ë§ˆí¬ë‹¤ìš´ ì² í•™ì— ë”°ë¥¸ í‚¤ êµ¬ì¡° ë¹„êµ
    
    í•µì‹¬ ì›ì¹™:
    1. "ê°’ì€ ë¸”ë™ë°•ìŠ¤" - ë©”íƒ€ë°ì´í„° í‚¤ì˜ ê°’ ë³€ê²½ì€ ë¬´ì‹œ
    2. "í—ˆìš©ëœ ìŠ¤ë©œ ìˆ˜ì •" - Tier-1 ìŠ¤ë©œ ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ í‚¤ ì¶”ê°€ëŠ” í—ˆìš©
    3. "í•µì‹¬ êµ¬ì¡° ë³´í˜¸" - jobs, steps ë“± ì›Œí¬í”Œë¡œìš° ë¼ˆëŒ€ëŠ” ì—„ê²©íˆ ë³´í˜¸
    """
    issues = []
    
    # 1. ì œê±°ëœ í‚¤ ê²€ì‚¬ (í•µì‹¬ êµ¬ì¡° í‚¤ ì œê±°ëŠ” ìœ„í—˜)
    removed_keys = set(orig_structure.keys()) - set(repaired_structure.keys())
    for key in removed_keys:
        if _is_critical_structural_key(key):
            issues.append(f"í•µì‹¬ êµ¬ì¡° í‚¤ ì œê±°: {key}")
        # ë©”íƒ€ë°ì´í„° í‚¤ ì œê±°ëŠ” í—ˆìš© (ì˜ˆ: name, env ë“±)
    
    # 2. ì¶”ê°€ëœ í‚¤ ê²€ì‚¬ (ìŠ¤ë©œ ìˆ˜ì • ê´€ë ¨ ì¶”ê°€ëŠ” í—ˆìš©)
    added_keys = set(repaired_structure.keys()) - set(orig_structure.keys())
    for key in added_keys:
        if not _is_allowed_key_addition_for_smell_fix(key):
            issues.append(f"ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ ì¶”ê°€: {key}")
    
    # 3. ê³µí†µ í‚¤ì˜ êµ¬ì¡° ë³€ê²½ ê²€ì‚¬
    common_keys = set(orig_structure.keys()) & set(repaired_structure.keys())
    for key in common_keys:
        orig_info = orig_structure[key]
        repaired_info = repaired_structure[key]
        
        # íƒ€ì… ë³€ê²½ ê²€ì‚¬ (ì¤‘ìš”í•œ êµ¬ì¡°ë§Œ)
        if orig_info["type"] != repaired_info["type"]:
            if _is_type_change_critical(key, orig_info["type"], repaired_info["type"]):
                issues.append(f"ì¤‘ìš” íƒ€ì… ë³€ê²½: {key} ({orig_info['type']} â†’ {repaired_info['type']})")
        
        # ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë³€ê²½ ê²€ì‚¬ (jobs, steps ë“±)
        elif orig_info["type"] == "list":
            if _is_list_length_critical(key):
                orig_length = orig_info.get("length", 0)
                repaired_length = repaired_info.get("length", 0)
                if orig_length != repaired_length:
                    issues.append(f"í•µì‹¬ ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë³€ê²½: {key} ({orig_length} â†’ {repaired_length})")
        
        # ë”•ì…”ë„ˆë¦¬ í‚¤ ìˆœì„œ ë³€ê²½ ê²€ì‚¬ (jobsë§Œ)
        elif orig_info["type"] == "dict":
            if _is_dict_key_order_critical(key):
                orig_keys = orig_info.get("keys", [])
                repaired_keys = repaired_info.get("keys", [])
                if orig_keys != repaired_keys:
                    issues.append(f"í•µì‹¬ ë”•ì…”ë„ˆë¦¬ í‚¤ ìˆœì„œ ë³€ê²½: {key}")
    
    return issues


def _is_critical_structural_key(key_path):
    """í•µì‹¬ êµ¬ì¡° í‚¤ì¸ì§€ íŒë‹¨ (ì œê±°ë˜ë©´ ìœ„í—˜)"""
    critical_patterns = [
        'root.jobs',           # ì „ì²´ jobs ë”•ì…”ë„ˆë¦¬
        'root.jobs.',          # ê°œë³„ job ì •ì˜
        '.steps',             # steps ë¦¬ìŠ¤íŠ¸
        '.needs',             # ì˜ì¡´ì„± ì •ì˜
        '.strategy.matrix',   # ë§¤íŠ¸ë¦­ìŠ¤ ì „ëµ
        '.runs-on'            # ì‹¤í–‰ í™˜ê²½
    ]
    
    return any(pattern in key_path for pattern in critical_patterns)


def _is_allowed_key_addition_for_smell_fix(key_path):
    """ìŠ¤ë©œ ìˆ˜ì •ìœ¼ë¡œ ì¸í•œ í—ˆìš©ëœ í‚¤ ì¶”ê°€ì¸ì§€ íŒë‹¨"""
    allowed_additions = [
        '.permissions',        # Smell 15: ê¶Œí•œ ì„¤ì • ì¶”ê°€
        '.timeout-minutes',    # Smell 10: íƒ€ì„ì•„ì›ƒ ì¶”ê°€
        '.concurrency',        # Smell 4, 5: ë™ì‹œì„± ì œì–´ ì¶”ê°€
        '.continue-on-error',  # ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
        '.if',                # Smell 9, 10: ì¡°ê±´ë¶€ ì‹¤í–‰ ì¶”ê°€
        '.on.',               # íŠ¸ë¦¬ê±° ì¡°ê±´ ê°œì„ 
        '.paths',             # Smell 16: ê²½ë¡œ í•„í„° ì¶”ê°€
        '.paths-ignore'       # Smell 16: ê²½ë¡œ ë¬´ì‹œ ì¶”ê°€
    ]
    
    return any(pattern in key_path for pattern in allowed_additions)


def _is_type_change_critical(key_path, orig_type, repaired_type):
    """íƒ€ì… ë³€ê²½ì´ ì¤‘ìš”í•œ êµ¬ì¡° ë³€ê²½ì¸ì§€ íŒë‹¨"""
    # jobs, steps ë“±ì˜ íƒ€ì… ë³€ê²½ì€ ì¹˜ëª…ì 
    critical_type_paths = [
        'root.jobs',
        '.steps',
        '.needs',
        '.strategy.matrix'
    ]
    
    if any(pattern in key_path for pattern in critical_type_paths):
        return True
    
    # ìŠ¤ì¹¼ë¼ â†’ ë”•ì…”ë„ˆë¦¬ ë³€ê²½ì€ êµ¬ì¡°ì  ê°œì„ ì¼ ìˆ˜ ìˆìŒ (ì˜ˆ: permissions: read-all â†’ permissions: {contents: read})
    if orig_type in ['str', 'bool', 'int'] and repaired_type == 'dict':
        if any(allowed in key_path for allowed in ['.permissions', '.with']):
            return False  # í—ˆìš©ëœ í™•ì¥
    
    return True  # ê¸°ë³¸ì ìœ¼ë¡œ íƒ€ì… ë³€ê²½ì€ ì¤‘ìš”


def _is_list_length_critical(key_path):
    """ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ ë³€ê²½ì´ ì¤‘ìš”í•œì§€ íŒë‹¨"""
    critical_list_paths = [
        'root.jobs',          # jobsëŠ” ë”•ì…”ë„ˆë¦¬ì§€ë§Œ ìˆœì„œ ì¤‘ìš”
        '.steps',            # steps ë¦¬ìŠ¤íŠ¸
        '.needs',            # needs ë¦¬ìŠ¤íŠ¸  
        '.strategy.matrix'   # matrix ë¦¬ìŠ¤íŠ¸
    ]
    
    return any(pattern in key_path for pattern in critical_list_paths)


def _is_dict_key_order_critical(key_path):
    """ë”•ì…”ë„ˆë¦¬ í‚¤ ìˆœì„œê°€ ì¤‘ìš”í•œì§€ íŒë‹¨"""
    # GitHub Actionsì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ í‚¤ ìˆœì„œê°€ ì˜ë¯¸ ì—†ìŒ
    # jobsëŠ” needsì— ì˜í•´ ì˜ì¡´ì„±ì´ ê²°ì •ë˜ë¯€ë¡œ ë”•ì…”ë„ˆë¦¬ ìˆœì„œëŠ” ë¬´ê´€
    # ë§ˆí¬ë‹¤ìš´ ì² í•™: "ê°’ì´ ê³§ êµ¬ì¡°"ì¸ í‚¤(needs, matrix)ë§Œ ì¤‘ìš”
    order_critical_paths = [
        # í˜„ì¬ëŠ” í‚¤ ìˆœì„œê°€ ì¤‘ìš”í•œ ê²½ìš°ê°€ ì—†ìŒ
        # jobs ë”•ì…”ë„ˆë¦¬ ìˆœì„œëŠ” needsì— ì˜í•´ ì‹¤í–‰ ìˆœì„œê°€ ê²°ì •ë˜ë¯€ë¡œ ë¬´ê´€
    ]
    
    return any(pattern in key_path for pattern in order_critical_paths)


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í•¨ìˆ˜
def verify_structural_equivalence(original_file: Path, repaired_file: Path):
    """ê¸°ì¡´ í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„±)"""
    result = verify_enhanced_structural_equivalence(original_file, repaired_file)
    return result["safe"]


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ì‚¬ìš©ë²•: python enhanced_key_structure_verifier.py <original_file> <repaired_file>")
        sys.exit(1)

    original_file = Path(sys.argv[1])
    repaired_file = Path(sys.argv[2])

    result = verify_enhanced_structural_equivalence(original_file, repaired_file)
    sys.exit(0 if result["safe"] else 1)
