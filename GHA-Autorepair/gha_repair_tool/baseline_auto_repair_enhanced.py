#!/usr/bin/env python3
"""
í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸

data_originalì˜ íŒŒì¼ë“¤ì„ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë“œë¡œ ë³µêµ¬í•˜ì—¬ ì¶œë ¥ ë””ë ‰í† ë¦¬ì— ì €ì¥
llama3.1:8b, codegemma:7b, codellama:7b ë“± ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›
"""

import logging
import sys
import os
from pathlib import Path
from typing import List, Dict, Optional
import time
from datetime import datetime
import json

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main import run_baseline_mode
from utils.llm_api import get_model_info, get_available_providers


class EnhancedBaselineAutoRepairer:
    """í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 input_dir: str, 
                 output_dir: str, 
                 log_file: str = None,
                 llm_provider: str = None,
                 llm_model: str = None,
                 ollama_url: str = None):
        """
        Args:
            input_dir: ì…ë ¥ ë””ë ‰í† ë¦¬ (data_original)
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (llama3.1_8b/data_repair_baseline ë“±)
            log_file: ê¸°ë³¸ ë¡œê·¸ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
            llm_provider: LLM ì œê³µì (openai, ollama)
            llm_model: ì‚¬ìš©í•  ëª¨ë¸ëª…
            ollama_url: Ollama ì„œë²„ URL
        """
        self.logger = logging.getLogger(__name__)
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.log_file = log_file
        
        # LLM ì„¤ì •
        self.llm_provider = llm_provider or os.getenv("LLM_PROVIDER", "openai")
        self.llm_model = llm_model or self._get_default_model()
        self.ollama_url = ollama_url or os.getenv("OLLAMA_URL", "http://115.145.178.160:11434/api/chat")
        
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        if self.llm_provider.lower() == "ollama":
            os.environ["LLM_PROVIDER"] = "ollama"
            if self.llm_model:
                os.environ["OLLAMA_MODEL"] = self.llm_model
            if self.ollama_url:
                os.environ["OLLAMA_URL"] = self.ollama_url
        else:
            os.environ["LLM_PROVIDER"] = "openai"
            if self.llm_model:
                os.environ["OPENAI_MODEL"] = self.llm_model
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # logs ë””ë ‰í† ë¦¬ ìƒì„±
        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)
        
        # ëª¨ë¸ ì •ë³´ ë¡œê¹…
        self._log_model_info()
        
        # ë¡œê·¸ íŒŒì¼ ì„¤ì •
        if log_file:
            self._setup_logging(logs_dir, log_file)
    
    def _get_default_model(self) -> str:
        """ì œê³µìì— ë”°ë¥¸ ê¸°ë³¸ ëª¨ë¸ ë°˜í™˜"""
        if self.llm_provider.lower() == "ollama":
            return "llama3.1:8b"
        else:
            return "gpt-4o-mini"
    
    def _log_model_info(self):
        """í˜„ì¬ LLM ì„¤ì • ì •ë³´ ë¡œê¹…"""
        try:
            model_info = get_model_info()
            available_providers = get_available_providers()
            
            self.logger.info("=" * 60)
            self.logger.info("ğŸ¤– LLM ì„¤ì • ì •ë³´")
            self.logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì: {available_providers}")
            self.logger.info(f"í˜„ì¬ ì œê³µì: {model_info.get('provider', 'unknown')}")
            self.logger.info(f"ëª¨ë¸ í‚¤: {model_info.get('model_key', 'unknown')}")
            self.logger.info(f"ì‹¤ì œ ëª¨ë¸: {model_info.get('actual_model', 'unknown')}")
            if model_info.get('url'):
                self.logger.info(f"ì„œë²„ URL: {model_info.get('url')}")
            self.logger.info("=" * 60)
        except Exception as e:
            self.logger.warning(f"ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    
    def _setup_logging(self, logs_dir: Path, log_file: str):
        """ë¡œê¹… ì„¤ì •"""
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±° ë° ëª¨ë¸ ì •ë³´ ì¶”ê°€
        base_name = Path(log_file).stem
        provider_model = f"{self.llm_provider}_{self.llm_model.replace(':', '_').replace('.', '_')}"
        base_name = f"{base_name}_{provider_model}"
        
        # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # 1. INFO ë ˆë²¨ íŒŒì¼ í•¸ë“¤ëŸ¬ (ìš”ì•½ ë¡œê·¸)
        info_file_handler = logging.FileHandler(
            logs_dir / f"{base_name}_info.log", 
            encoding='utf-8'
        )
        info_file_handler.setLevel(logging.INFO)
        info_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        info_file_handler.setFormatter(info_formatter)
        
        # INFO ë ˆë²¨ë§Œ í•„í„°ë§í•˜ëŠ” í•„í„° ì¶”ê°€
        info_filter = logging.Filter()
        info_filter.filter = lambda record: record.levelno >= logging.INFO and record.levelno < logging.ERROR
        info_file_handler.addFilter(info_filter)
        root_logger.addHandler(info_file_handler)
        
        # 2. DEBUG ë ˆë²¨ íŒŒì¼ í•¸ë“¤ëŸ¬ (ìƒì„¸ ë¡œê·¸)
        debug_file_handler = logging.FileHandler(
            logs_dir / f"{base_name}_debug.log", 
            encoding='utf-8'
        )
        debug_file_handler.setLevel(logging.DEBUG)
        debug_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        debug_file_handler.setFormatter(debug_formatter)
        root_logger.addHandler(debug_file_handler)
        
        # 3. ì½˜ì†” í•¸ë“¤ëŸ¬ (í„°ë¯¸ë„ ì¶œë ¥ - INFO ë ˆë²¨ë§Œ)
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(info_formatter)
        root_logger.addHandler(console_handler)
        
        self.info_log_path = logs_dir / f"{base_name}_info.log"
        self.debug_log_path = logs_dir / f"{base_name}_debug.log"
    
    def repair_all_files(self, max_files: int = None, start_from: int = 0) -> Dict[str, any]:
        """
        ëª¨ë“  íŒŒì¼ì„ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë“œë¡œ ë³µêµ¬í•©ë‹ˆë‹¤.
        
        Args:
            max_files: ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
            start_from: ì‹œì‘í•  íŒŒì¼ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        """
        # ì…ë ¥ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        input_files = list(self.input_dir.glob("*"))
        input_files = [f for f in input_files if f.is_file()]
        input_files.sort()  # ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
        
        # ì‹œì‘ì ê³¼ ìµœëŒ€ íŒŒì¼ ìˆ˜ ì ìš©
        if start_from > 0:
            input_files = input_files[start_from:]
        
        if max_files:
            input_files = input_files[:max_files]
        
        total_files = len(input_files)
        self.logger.info(f"í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ ì‹œì‘: {total_files}ê°œ íŒŒì¼")
        self.logger.info(f"ì…ë ¥ ë””ë ‰í† ë¦¬: {self.input_dir}")
        self.logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
        if start_from > 0:
            self.logger.info(f"ì‹œì‘ ì¸ë±ìŠ¤: {start_from}")
        
        start_time = datetime.now()
        successful_repairs = []
        failed_repairs = []
        
        for i, input_file in enumerate(input_files, 1):
            actual_index = start_from + i
            self.logger.info(f"[{i}/{total_files}] (ì „ì²´ #{actual_index}) ì²˜ë¦¬ ì¤‘: {input_file.name}")
            
            try:
                # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„± (ëª¨ë¸ ì •ë³´ í¬í•¨)
                provider_model = f"{self.llm_provider}_{self.llm_model.replace(':', '_').replace('.', '_')}"
                output_file = self.output_dir / f"{input_file.name}_{provider_model}_baseline_repaired.yml"
                
                # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ê±´ë„ˆë›°ê¸° (ì¬ì‹œì‘ ì§€ì›)
                if output_file.exists():
                    self.logger.info(f"â­ï¸  ê±´ë„ˆë›°ê¸° (ì´ë¯¸ ì¡´ì¬): {output_file.name}")
                    successful_repairs.append({
                        'input_file': str(input_file),
                        'output_file': str(output_file),
                        'processing_time': 0.0,
                        'skipped': True
                    })
                    continue
                
                # ë² ì´ìŠ¤ë¼ì¸ ë³µêµ¬ ì‹¤í–‰
                self.logger.info(f"=== íŒŒì¼ {i}/{total_files} ë² ì´ìŠ¤ë¼ì¸ ë³µêµ¬ ì‹œì‘ ===")
                file_start_time = time.time()
                success = run_baseline_mode(str(input_file), str(output_file))
                processing_time = time.time() - file_start_time
                self.logger.info(f"=== íŒŒì¼ {i}/{total_files} ë² ì´ìŠ¤ë¼ì¸ ë³µêµ¬ ì™„ë£Œ ===")
                
                if success and output_file.exists():
                    file_size = output_file.stat().st_size
                    successful_repairs.append({
                        'input_file': str(input_file),
                        'output_file': str(output_file),
                        'processing_time': processing_time,
                        'file_size': file_size,
                        'skipped': False
                    })
                    self.logger.info(f"âœ… ì„±ê³µ ({processing_time:.2f}ì´ˆ, {file_size} bytes): {input_file.name}")
                else:
                    failed_repairs.append({
                        'input_file': str(input_file),
                        'error': 'Baseline repair failed or output file not created',
                        'processing_time': processing_time
                    })
                    self.logger.error(f"âŒ ì‹¤íŒ¨ ({processing_time:.2f}ì´ˆ): {input_file.name}")
                    
            except KeyboardInterrupt:
                self.logger.warning(f"ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ (Ctrl+C)")
                break
                    
            except Exception as e:
                failed_repairs.append({
                    'input_file': str(input_file),
                    'error': str(e),
                    'processing_time': 0.0
                })
                self.logger.error(f"âŒ ì˜¤ë¥˜: {input_file.name} - {e}")
                self.logger.exception(f"ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
                
                # ì¹˜ëª…ì  ì˜¤ë¥˜ì¸ ê²½ìš° ì¤‘ë‹¨ ê³ ë ¤
                if "connection" in str(e).lower() or "timeout" in str(e).lower():
                    self.logger.error("ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ê°ì§€. ì ì‹œ ëŒ€ê¸° í›„ ê³„ì†...")
                    time.sleep(5)
        
        total_processing_time = (datetime.now() - start_time).total_seconds()
        
        # ê²°ê³¼ ìš”ì•½
        summary = {
            'model_info': {
                'provider': self.llm_provider,
                'model': self.llm_model,
                'url': self.ollama_url if self.llm_provider.lower() == "ollama" else None
            },
            'execution_info': {
                'start_time': start_time.isoformat(),
                'end_time': datetime.now().isoformat(),
                'total_processing_time': total_processing_time,
                'start_from': start_from,
                'requested_files': max_files,
                'processed_files': len(input_files)
            },
            'results': {
                'total_files': total_files,
                'successful_repairs': len(successful_repairs),
                'failed_repairs': len(failed_repairs),
                'success_rate': (len(successful_repairs) / total_files) * 100.0 if total_files > 0 else 0.0,
                'avg_processing_time': sum(r.get('processing_time', 0) for r in successful_repairs + failed_repairs) / total_files if total_files > 0 else 0.0,
            },
            'detailed_results': {
                'successful_files': successful_repairs,
                'failed_files': failed_repairs
            }
        }
        
        # ê²°ê³¼ JSON ì €ì¥
        self._save_results(summary)
        
        # ê²°ê³¼ ë¡œê¹…
        self._log_summary(summary)
        
        return summary
    
    def _save_results(self, summary: Dict):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            provider_model = f"{self.llm_provider}_{self.llm_model.replace(':', '_').replace('.', '_')}"
            results_file = self.output_dir / f"batch_results_{provider_model}_{timestamp}.json"
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ê²°ê³¼ JSON ì €ì¥: {results_file}")
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _log_summary(self, summary: Dict):
        """ê²°ê³¼ ìš”ì•½ ë¡œê¹…"""
        results = summary['results']
        model_info = summary['model_info']
        
        self.logger.info("=" * 60)
        self.logger.info("ğŸ‰ í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ ì™„ë£Œ!")
        self.logger.info(f"ì‚¬ìš© ëª¨ë¸: {model_info['provider']} / {model_info['model']}")
        self.logger.info(f"ì´ ì²˜ë¦¬ ì‹œê°„: {summary['execution_info']['total_processing_time']:.1f}ì´ˆ")
        self.logger.info(f"ì´ íŒŒì¼: {results['total_files']}")
        self.logger.info(f"ì„±ê³µ: {results['successful_repairs']} ({results['success_rate']:.1f}%)")
        self.logger.info(f"ì‹¤íŒ¨: {results['failed_repairs']}")
        self.logger.info(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {results['avg_processing_time']:.2f}ì´ˆ/íŒŒì¼")
        self.logger.info(f"ì¶œë ¥ íŒŒì¼ ìœ„ì¹˜: {self.output_dir}")
        if hasattr(self, 'info_log_path') and hasattr(self, 'debug_log_path'):
            self.logger.info(f"INFO ë¡œê·¸ íŒŒì¼: {self.info_log_path}")
            self.logger.info(f"DEBUG ë¡œê·¸ íŒŒì¼: {self.debug_log_path}")
        self.logger.info("=" * 60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ ë„êµ¬")
    parser.add_argument("--input-dir", required=True, help="ì…ë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--output-dir", required=True, help="ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--max-files", type=int, help="ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜")
    parser.add_argument("--start-from", type=int, default=0, help="ì‹œì‘í•  íŒŒì¼ ì¸ë±ìŠ¤")
    parser.add_argument("--log-file", help="ë¡œê·¸ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    
    # LLM ì„¤ì •
    parser.add_argument("--llm-provider", choices=["openai", "ollama"], help="LLM ì œê³µì")
    parser.add_argument("--llm-model", help="ì‚¬ìš©í•  ëª¨ë¸ëª…")
    parser.add_argument("--ollama-url", help="Ollama ì„œë²„ URL")
    
    args = parser.parse_args()
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ìë™ ìƒì„±
    if not args.log_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        provider = args.llm_provider or os.getenv("LLM_PROVIDER", "openai")
        args.log_file = f"enhanced_baseline_repair_{provider}_{timestamp}"
    
    # ê¸°ë³¸ ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[]  # í•¸ë“¤ëŸ¬ëŠ” EnhancedBaselineAutoRepairerì—ì„œ ì„¤ì •
    )
    
    try:
        repairer = EnhancedBaselineAutoRepairer(
            input_dir=args.input_dir,
            output_dir=args.output_dir,
            log_file=args.log_file,
            llm_provider=args.llm_provider,
            llm_model=args.llm_model,
            ollama_url=args.ollama_url
        )
        
        summary = repairer.repair_all_files(
            max_files=args.max_files,
            start_from=args.start_from
        )
        
        results = summary['results']
        model_info = summary['model_info']
        
        print(f"\nğŸ‰ í–¥ìƒëœ ë² ì´ìŠ¤ë¼ì¸ ìë™ ë³µêµ¬ ì™„ë£Œ!")
        print(f"ì‚¬ìš© ëª¨ë¸: {model_info['provider']} / {model_info['model']}")
        print(f"ì´ íŒŒì¼: {results['total_files']}")
        print(f"ì„±ê³µ: {results['successful_repairs']}")
        print(f"ì‹¤íŒ¨: {results['failed_repairs']}")
        print(f"ì„±ê³µë¥ : {results['success_rate']:.1f}%")
        print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {summary['execution_info']['total_processing_time']:.1f}ì´ˆ")
        
        if hasattr(repairer, 'info_log_path') and hasattr(repairer, 'debug_log_path'):
            print(f"INFO ë¡œê·¸: {repairer.info_log_path}")
            print(f"DEBUG ë¡œê·¸: {repairer.debug_log_path}")
        
        return results['failed_repairs'] == 0
        
    except KeyboardInterrupt:
        print("\nâŒ ì‚¬ìš©ì ì¤‘ë‹¨ (Ctrl+C)")
        return False
        
    except Exception as e:
        logging.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
