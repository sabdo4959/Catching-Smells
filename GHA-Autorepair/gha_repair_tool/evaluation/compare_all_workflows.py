#!/usr/bin/env python3
"""
/Users/nam/workflows/ ì „ì²´ íŒŒì¼ ë¹„êµ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

step1ê³¼ step2 íŒŒì¼ë“¤ì„ ëª¨ë‘ ë¹„êµí•˜ì—¬:
1. ì „ì²´ íŒŒì¼ í†µê³„
2. actionlint í†µê³¼ íŒŒì¼ë§Œì˜ í†µê³„
3. actionlint í†µê³¼ + BLEU >= 0.85 íŒŒì¼ í†µê³„
"""

import logging
import argparse
import sys
import os
import json
import csv
import yaml
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime
import pandas as pd
import difflib
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils import process_runner


class AllWorkflowsComparator:
    """ì „ì²´ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë¹„êµ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "./evaluation/all_workflows_comparison"):
        """
        Args:
            output_dir: ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.logger = logging.getLogger(__name__)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def check_yaml_syntax(self, file_path: str) -> Tuple[bool, str]:
        """YAML íŒŒì‹± ê²€ì¦"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            yaml_data = yaml.safe_load(content)
            if yaml_data is not None:
                return True, None
            else:
                return False, "Empty YAML file"
        except yaml.YAMLError as e:
            return False, str(e)
        except Exception as e:
            return False, f"Unknown error: {str(e)}"
    
    def check_with_actionlint(self, file_path: str) -> Tuple[bool, List, List, List]:
        """
        actionlint ê²€ì¦
        
        Returns:
            Tuple[valid, all_errors, syntax_errors, expression_errors]
        """
        try:
            result = process_runner.run_actionlint(file_path)
            
            if result.get('success', True):
                return True, [], [], []
            else:
                all_errors = result.get('errors', [])
                
                # syntax-checkì™€ expression ì˜¤ë¥˜ë§Œ í•„í„°ë§
                syntax_errors = [
                    error for error in all_errors 
                    if isinstance(error, dict) and error.get('kind') == 'syntax-check'
                ]
                expression_errors = [
                    error for error in all_errors 
                    if isinstance(error, dict) and error.get('kind') == 'expression'
                ]
                
                # syntax-check, expression ì˜¤ë¥˜ë§Œ ìˆìœ¼ë©´ ì‹¤íŒ¨
                is_valid = len(syntax_errors) == 0 and len(expression_errors) == 0
                
                return is_valid, all_errors, syntax_errors, expression_errors
                
        except Exception as e:
            self.logger.error(f"actionlint ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            error_obj = {'message': str(e), 'kind': 'runtime-error'}
            return False, [error_obj], [], []
    
    def calculate_edit_distance(self, file1: str, file2: str) -> int:
        """ë‘ íŒŒì¼ ê°„ì˜ Edit Distance ê³„ì‚° (Line-level)"""
        try:
            with open(file1, 'r', encoding='utf-8') as f:
                content1_lines = f.readlines()
            with open(file2, 'r', encoding='utf-8') as f:
                content2_lines = f.readlines()
            
            matcher = difflib.SequenceMatcher(None, content1_lines, content2_lines)
            opcodes = matcher.get_opcodes()
            edit_distance = 0
            
            for op, i1, i2, j1, j2 in opcodes:
                if op == 'replace':
                    edit_distance += max(i2 - i1, j2 - j1)
                elif op == 'delete':
                    edit_distance += i2 - i1
                elif op == 'insert':
                    edit_distance += j2 - j1
            
            return edit_distance
            
        except Exception as e:
            self.logger.error(f"Edit distance ê³„ì‚° ì˜¤ë¥˜: {e}")
            return -1
    
    def calculate_bleu_score(self, file1: str, file2: str) -> float:
        """ë‘ íŒŒì¼ ê°„ì˜ BLEU Score ê³„ì‚°"""
        try:
            with open(file1, 'r', encoding='utf-8') as f:
                reference = f.read()
            with open(file2, 'r', encoding='utf-8') as f:
                hypothesis = f.read()
            
            # í† í°í™”: ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            reference_tokens = [reference.split('\n')]
            candidate_tokens = hypothesis.split('\n')
            
            # Smoothing function ì‚¬ìš©
            smoothing = SmoothingFunction().method1
            
            # BLEU score ê³„ì‚°
            bleu = sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)
            return bleu
            
        except Exception as e:
            self.logger.error(f"BLEU score ê³„ì‚° ì˜¤ë¥˜: {e}")
            return -1.0
    
    def find_step_pairs_all(self, workflows_dir: str, max_files: int = None) -> Dict[str, List[Tuple[str, str]]]:
        """
        workflows ë””ë ‰í† ë¦¬ì—ì„œ step1ê³¼ step2, 3, 4, 5ì˜ ëª¨ë“  íŒŒì¼ ìŒì„ ì°¾ìŠµë‹ˆë‹¤.
        os.scandir()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ íƒìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            workflows_dir: ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë””ë ‰í† ë¦¬
            max_files: ê° stepë³„ ìµœëŒ€ íŒŒì¼ ìˆ˜
            
        Returns:
            Dict[str, List[Tuple[step1_path, stepN_path]]]: 
                í‚¤: 'step2', 'step3', 'step4', 'step5'
                ê°’: íŒŒì¼ ìŒ ë¦¬ìŠ¤íŠ¸
        """
        import os
        
        if not os.path.exists(workflows_dir):
            raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {workflows_dir}")
        
        self.logger.info(f"íŒŒì¼ ìŒ íƒìƒ‰ ì‹œì‘: {workflows_dir}")
        
        # step1 íŒŒì¼ë“¤ì„ ë¨¼ì € ìˆ˜ì§‘ (ë”•ì…”ë„ˆë¦¬ë¡œ ë¹ ë¥¸ ì¡°íšŒ)
        step1_files = {}
        step1_count = 0
        
        self.logger.info("Step1 íŒŒì¼ íƒìƒ‰ ì¤‘...")
        
        try:
            with os.scandir(workflows_dir) as entries:
                for entry in entries:
                    # íŒŒì¼ëª…ë§Œ ì²´í¬ (is_file() í˜¸ì¶œ ì•ˆ í•¨ - ëŠë¦¼)
                    if entry.name.endswith('_step1.yaml') or entry.name.endswith('_step1.yml'):
                        base_name = entry.name.replace('_step1.yaml', '').replace('_step1.yml', '')
                        step1_files[base_name] = entry.path
                        step1_count += 1
                        
                        if step1_count % 1000 == 0:
                            self.logger.info(f"  Step1: {step1_count}ê°œ íŒŒì¼ ë°œê²¬...")
                        
                        # max_files ì œí•œ (step1ë„ ì œí•œ)
                        if max_files and step1_count >= max_files * 2:  # ì—¬ìœ ìˆê²Œ 2ë°°
                            self.logger.info(f"  Step1: {max_files * 2}ê°œ ì œí•œ ë„ë‹¬, íƒìƒ‰ ì¤‘ë‹¨")
                            break
                            
        except Exception as e:
            self.logger.error(f"Step1 íŒŒì¼ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
        
        if not step1_files:
            raise ValueError("step1 íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
        
        self.logger.info(f"âœ… Step1: ì´ {len(step1_files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        # ê° stepë³„ë¡œ íŒŒì¼ ìŒ ìƒì„±
        all_pairs = {}
        
        for step_num in [2, 3, 4, 5]:
            step_key = f'step{step_num}'
            file_pairs = []
            stepN_count = 0
            matched_count = 0
            
            self.logger.info(f"\n{step_key.upper()} íŒŒì¼ íƒìƒ‰ ì¤‘...")
            
            try:
                with os.scandir(workflows_dir) as entries:
                    for entry in entries:
                        # stepN íŒŒì¼ ì²´í¬ (íŒŒì¼ëª…ë§Œ)
                        if entry.name.endswith(f'_step{step_num}.yaml') or entry.name.endswith(f'_step{step_num}.yml'):
                            stepN_count += 1
                            
                            if stepN_count % 1000 == 0:
                                self.logger.info(f"  {step_key}: {stepN_count}ê°œ íŒŒì¼ ìŠ¤ìº” ì¤‘...")
                            
                            base_name = entry.name.replace(f'_step{step_num}.yaml', '').replace(f'_step{step_num}.yml', '')
                            
                            if base_name in step1_files:
                                step1_path = step1_files[base_name]
                                file_pairs.append((step1_path, entry.path))
                                matched_count += 1
                                
                                # max_files ì œí•œ í™•ì¸
                                if max_files and matched_count >= max_files:
                                    self.logger.info(f"  {step_key}: {max_files}ê°œ ì œí•œ ë„ë‹¬, íƒìƒ‰ ì¤‘ë‹¨")
                                    break
                                    
            except Exception as e:
                self.logger.error(f"{step_key} íŒŒì¼ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            
            all_pairs[step_key] = file_pairs
            self.logger.info(f"âœ… {step_key.upper()}: {stepN_count}ê°œ ì¤‘ {matched_count}ê°œ ë§¤ì¹­ë¨")
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("ğŸ“ Stepë³„ íŒŒì¼ ë§¤ì¹­ ê²°ê³¼")
        print("=" * 80)
        print(f"Step1: {len(step1_files)}ê°œ íŒŒì¼ (ê¸°ì¤€)")
        for step_num in [2, 3, 4, 5]:
            step_key = f'step{step_num}'
            count = len(all_pairs[step_key])
            print(f"Step{step_num}: {count}ê°œ íŒŒì¼ ìŒ ë§¤ì¹­ë¨")
        print("=" * 80 + "\n")
        
        return all_pairs
    
    def compare_all_workflows_by_dirs(self, 
                                      step_dirs: Dict[str, str],
                                      csv_file: str = None,
                                      max_files: int = None) -> Dict:
        """
        ë³„ë„ ë””ë ‰í† ë¦¬ì— ìˆëŠ” step íŒŒì¼ë“¤ì„ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤.
        step1ê³¼ step2, 3, 4, 5ë¥¼ ê°ê° ë¹„êµí•©ë‹ˆë‹¤.
        
        Args:
            step_dirs: {'step1': path, 'step2': path, ...} ë””ë ‰í† ë¦¬ ì •ë³´
            csv_file: step ë§¤í•‘ ì •ë³´ë¥¼ ë‹´ì€ CSV íŒŒì¼ ê²½ë¡œ
            max_files: í‰ê°€í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (ê° stepë³„ë¡œ ì ìš©)
            
        Returns:
            Dict: ë¹„êµ í‰ê°€ ê²°ê³¼ (stepë³„ë¡œ êµ¬ë¶„)
        """
        import csv as csv_module
        
        start_time = datetime.now()
        
        # CSVì—ì„œ step ë§¤í•‘ ì •ë³´ ì½ê¸°
        if csv_file is None:
            csv_file = "/Users/nam/Desktop/repository/Catching-Smells/data/all_steps.csv"
        
        self.logger.info(f"CSV íŒŒì¼ ë¡œë”© ì¤‘: {csv_file}")
        step_mappings = {}  # {step1_hash: {'step2': step2_hash, 'step3': step3_hash, ...}}
        
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv_module.DictReader(f)
            for row in reader:
                step1_hash = row['file_hash_step1']
                if not step1_hash or step1_hash.strip() == '':
                    continue
                
                step_mappings[step1_hash] = {
                    'step2': row.get('file_hash_step2', ''),
                    'step3': row.get('file_hash_step3', ''),
                    'step4': row.get('file_hash_step4', ''),
                    'step5': row.get('file_hash_step5', '')
                }
        
        self.logger.info(f"âœ… CSVì—ì„œ {len(step_mappings)}ê°œ ë§¤í•‘ ë¡œë“œë¨")
        
        # step1 íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ (íŒŒì¼ëª… â†’ ê²½ë¡œ)
        step1_dir = Path(step_dirs['step1'])
        if not step1_dir.exists():
            raise FileNotFoundError(f"Step1 ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {step1_dir}")
        
        self.logger.info(f"Step1 íŒŒì¼ ìˆ˜ì§‘ ì¤‘: {step1_dir}")
        step1_files = {}
        
        # í™•ì¥ì ì—†ëŠ” íŒŒì¼ ìˆ˜ì§‘ (í•´ì‹œê°’ë§Œ ìˆëŠ” íŒŒì¼ëª…)
        for file_path in step1_dir.iterdir():
            if file_path.is_file():
                file_hash = file_path.name  # íŒŒì¼ëª… ì „ì²´ê°€ í•´ì‹œ
                # CSVì— ë§¤í•‘ ì •ë³´ê°€ ìˆëŠ” íŒŒì¼ë§Œ ìˆ˜ì§‘
                if file_hash in step_mappings:
                    step1_files[file_hash] = str(file_path)
        
        total_step1 = len(step1_files)
        self.logger.info(f"âœ… Step1: {total_step1}ê°œ íŒŒì¼ ë°œê²¬ (CSV ë§¤í•‘ ìˆìŒ)")
        
        # max_files ì œí•œ ì ìš©
        if max_files and total_step1 > max_files:
            step1_files = dict(list(step1_files.items())[:max_files])
            self.logger.info(f"  Step1: {max_files}ê°œë¡œ ì œí•œ")
        
        # ê° stepë³„ë¡œ íŒŒì¼ ìŒ ìƒì„± ë° í‰ê°€
        all_step_results = {}
        
        for step_num in [2, 3, 4, 5]:
            step_key = f'step{step_num}'
            step_dir = Path(step_dirs[step_key])
            
            if not step_dir.exists():
                self.logger.warning(f"{step_key} ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {step_dir}")
                all_step_results[step_key] = {
                    'file_pairs_count': 0,
                    'results': [],
                    'stats': None
                }
                continue
            
            self.logger.info(f"\n{step_key.upper()} íŒŒì¼ ë§¤ì¹­ ì¤‘...")
            
            # CSV ë§¤í•‘ì„ ì‚¬ìš©í•´ì„œ íŒŒì¼ ìŒ ìƒì„±
            file_pairs = []
            
            for step1_hash, step1_path in step1_files.items():
                # CSVì—ì„œ í•´ë‹¹ stepNì˜ í•´ì‹œê°’ ì°¾ê¸°
                stepN_hash = step_mappings[step1_hash].get(step_key, '')
                
                if not stepN_hash or stepN_hash.strip() == '':
                    continue
                
                # stepN íŒŒì¼ ê²½ë¡œ ìƒì„±
                stepN_path = step_dir / stepN_hash
                
                if stepN_path.exists():
                    file_pairs.append((step1_path, str(stepN_path)))
            
            total_pairs = len(file_pairs)
            self.logger.info(f"âœ… {step_key}: {total_pairs}ê°œ íŒŒì¼ ìŒ ë§¤ì¹­ë¨")
            
            if total_pairs == 0:
                all_step_results[step_key] = {
                    'file_pairs_count': 0,
                    'results': [],
                    'stats': None
                }
                continue
            
            # í‰ê°€ ìˆ˜í–‰
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ” {step_key.upper()} ë¹„êµ í‰ê°€ ì‹œì‘: {total_pairs}ê°œ íŒŒì¼ ìŒ")
            self.logger.info(f"{'='*60}")
            
            step_results = []
            
            for i, (step1_file, stepN_file) in enumerate(file_pairs, 1):
                if i % 100 == 0 or i == 1:
                    self.logger.info(f"[{step_key}] [{i}/{total_pairs}] í‰ê°€ ì¤‘... ({i/total_pairs*100:.1f}%)")
                
                # step1 ê²€ì¦
                step1_yaml_valid, step1_yaml_error = self.check_yaml_syntax(step1_file)
                step1_actionlint_valid, step1_all_errors, step1_syntax_errors, step1_expression_errors = \
                    self.check_with_actionlint(step1_file)
                
                # stepN ê²€ì¦
                stepN_yaml_valid, stepN_yaml_error = self.check_yaml_syntax(stepN_file)
                stepN_actionlint_valid, stepN_all_errors, stepN_syntax_errors, stepN_expression_errors = \
                    self.check_with_actionlint(stepN_file)
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                edit_distance = self.calculate_edit_distance(step1_file, stepN_file)
                bleu_score = self.calculate_bleu_score(step1_file, stepN_file)
                
                result = {
                    'base_name': Path(step1_file).stem,
                    'step1_file': Path(step1_file).name,
                    f'{step_key}_file': Path(stepN_file).name,
                    
                    # step1 ê²°ê³¼
                    'step1_yaml_valid': step1_yaml_valid,
                    'step1_yaml_error': step1_yaml_error,
                    'step1_actionlint_valid': step1_actionlint_valid,
                    'step1_syntax_error_count': len(step1_syntax_errors),
                    'step1_expression_error_count': len(step1_expression_errors),
                    
                    # stepN ê²°ê³¼
                    f'{step_key}_yaml_valid': stepN_yaml_valid,
                    f'{step_key}_yaml_error': stepN_yaml_error,
                    f'{step_key}_actionlint_valid': stepN_actionlint_valid,
                    f'{step_key}_syntax_error_count': len(stepN_syntax_errors),
                    f'{step_key}_expression_error_count': len(stepN_expression_errors),
                    
                    # ìœ ì‚¬ë„
                    'edit_distance': edit_distance,
                    'bleu_score': bleu_score,
                    
                    # ê°œì„  ì—¬ë¶€
                    'yaml_improved': stepN_yaml_valid and not step1_yaml_valid,
                    'actionlint_improved': stepN_actionlint_valid and not step1_actionlint_valid,
                }
                
                step_results.append(result)
            
            # stepë³„ í†µê³„ ê³„ì‚°
            step_stats = self._calculate_step_statistics(step_results, total_pairs, step_key)
            
            all_step_results[step_key] = {
                'file_pairs_count': total_pairs,
                'results': step_results,
                'stats': step_stats
            }
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # ì „ì²´ ìš”ì•½
        summary = {
            'metadata': {
                'step_dirs': step_dirs,
                'csv_file': csv_file,
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat()
            },
            'step_results': all_step_results
        }
        
        # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
        self.save_comparison_results(summary)
        self.print_comparison_summary(summary)
        
        return summary
    
    def compare_all_workflows(self, 
                              workflows_dir: str,
                              max_files: int = None) -> Dict:
        """
        ì „ì²´ ì›Œí¬í”Œë¡œìš° íŒŒì¼ì„ ë¹„êµ í‰ê°€í•©ë‹ˆë‹¤.
        step1ê³¼ step2, 3, 4, 5ë¥¼ ê°ê° ë¹„êµí•©ë‹ˆë‹¤.
        
        Args:
            workflows_dir: ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë””ë ‰í† ë¦¬
            max_files: í‰ê°€í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (ê° stepë³„ë¡œ ì ìš©)
            
        Returns:
            Dict: ë¹„êµ í‰ê°€ ê²°ê³¼ (stepë³„ë¡œ êµ¬ë¶„)
        """
        start_time = datetime.now()
        
        # ëª¨ë“  step íŒŒì¼ ìŒ ì°¾ê¸° (max_files ì œí•œ í¬í•¨)
        all_step_pairs = self.find_step_pairs_all(workflows_dir, max_files)
        
        # ê° stepë³„ë¡œ í‰ê°€ ìˆ˜í–‰
        all_step_results = {}
        
        for step_key in ['step2', 'step3', 'step4', 'step5']:
            file_pairs = all_step_pairs[step_key]
            
            if not file_pairs:
                self.logger.warning(f"{step_key}: ë§¤ì¹­ë˜ëŠ” íŒŒì¼ ìŒì´ ì—†ìŠµë‹ˆë‹¤")
                all_step_results[step_key] = {
                    'file_pairs_count': 0,
                    'results': [],
                    'stats': None
                }
                continue
            
            total_pairs = len(file_pairs)
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ” {step_key.upper()} ë¹„êµ í‰ê°€ ì‹œì‘: {total_pairs}ê°œ íŒŒì¼ ìŒ")
            self.logger.info(f"{'='*60}")
            
            # íŒŒì¼ í‰ê°€
            step_results = []
            
            for i, (step1_file, stepN_file) in enumerate(file_pairs, 1):
                if i % 10 == 0 or i == 1:
                    self.logger.info(f"[{step_key}] [{i}/{total_pairs}] í‰ê°€ ì¤‘... ({i/total_pairs*100:.1f}%)")
                
                # step1 ê²€ì¦
                step1_yaml_valid, step1_yaml_error = self.check_yaml_syntax(step1_file)
                step1_actionlint_valid, step1_all_errors, step1_syntax_errors, step1_expression_errors = \
                    self.check_with_actionlint(step1_file)
                
                # stepN ê²€ì¦
                stepN_yaml_valid, stepN_yaml_error = self.check_yaml_syntax(stepN_file)
                stepN_actionlint_valid, stepN_all_errors, stepN_syntax_errors, stepN_expression_errors = \
                    self.check_with_actionlint(stepN_file)
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                edit_distance = self.calculate_edit_distance(step1_file, stepN_file)
                bleu_score = self.calculate_bleu_score(step1_file, stepN_file)
                
                result = {
                    'base_name': Path(step1_file).stem.replace('_step1', ''),
                    'step1_file': Path(step1_file).name,
                    f'{step_key}_file': Path(stepN_file).name,
                    
                    # step1 ê²°ê³¼
                    'step1_yaml_valid': step1_yaml_valid,
                    'step1_yaml_error': step1_yaml_error,
                    'step1_actionlint_valid': step1_actionlint_valid,
                    'step1_syntax_error_count': len(step1_syntax_errors),
                    'step1_expression_error_count': len(step1_expression_errors),
                    
                    # stepN ê²°ê³¼
                    f'{step_key}_yaml_valid': stepN_yaml_valid,
                    f'{step_key}_yaml_error': stepN_yaml_error,
                    f'{step_key}_actionlint_valid': stepN_actionlint_valid,
                    f'{step_key}_syntax_error_count': len(stepN_syntax_errors),
                    f'{step_key}_expression_error_count': len(stepN_expression_errors),
                    
                    # ìœ ì‚¬ë„
                    'edit_distance': edit_distance,
                    'bleu_score': bleu_score,
                    
                    # ê°œì„  ì—¬ë¶€
                    'yaml_improved': stepN_yaml_valid and not step1_yaml_valid,
                    'actionlint_improved': stepN_actionlint_valid and not step1_actionlint_valid,
                }
                
                step_results.append(result)
            
            # stepë³„ í†µê³„ ê³„ì‚°
            step_stats = self._calculate_step_statistics(step_results, total_pairs, step_key)
            
            all_step_results[step_key] = {
                'file_pairs_count': total_pairs,
                'results': step_results,
                'stats': step_stats
            }
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # ì „ì²´ ìš”ì•½
        summary = {
            'metadata': {
                'workflows_dir': workflows_dir,
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat()
            },
            'step_results': all_step_results
        }
        
        # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
        self.save_comparison_results(summary)
        self.print_comparison_summary(summary)
        
        return summary
    
    def _calculate_step_statistics(self, results: List[Dict], total: int, step_key: str) -> Dict:
        """
        íŠ¹ì • stepì˜ í†µê³„ ê³„ì‚°
        
        Args:
            results: í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            total: ì „ì²´ íŒŒì¼ ìˆ˜
            step_key: 'step2', 'step3', 'step4', 'step5'
        """
        if total == 0:
            return {
                'overall': {},
                'actionlint_passed': {},
                'high_quality': {}
            }
        
        # 1. ì „ì²´ íŒŒì¼ í†µê³„
        step1_yaml_success = sum(1 for r in results if r['step1_yaml_valid'])
        step1_actionlint_success = sum(1 for r in results if r['step1_actionlint_valid'])
        
        stepN_yaml_success = sum(1 for r in results if r.get(f'{step_key}_yaml_valid', False))
        stepN_actionlint_success = sum(1 for r in results if r.get(f'{step_key}_actionlint_valid', False))
        
        yaml_improved = sum(1 for r in results if r['yaml_improved'])
        actionlint_improved = sum(1 for r in results if r['actionlint_improved'])
        
        valid_bleu = [r['bleu_score'] for r in results if r['bleu_score'] >= 0]
        valid_edit = [r['edit_distance'] for r in results if r['edit_distance'] >= 0]
        
        overall_stats = {
            'total_files': total,
            'step1': {
                'yaml_success': step1_yaml_success,
                'yaml_success_rate': (step1_yaml_success / total * 100) if total > 0 else 0,
                'actionlint_success': step1_actionlint_success,
                'actionlint_success_rate': (step1_actionlint_success / total * 100) if total > 0 else 0,
            },
            f'{step_key}': {
                'yaml_success': stepN_yaml_success,
                'yaml_success_rate': (stepN_yaml_success / total * 100) if total > 0 else 0,
                'actionlint_success': stepN_actionlint_success,
                'actionlint_success_rate': (stepN_actionlint_success / total * 100) if total > 0 else 0,
            },
            'improvement': {
                'yaml_improved_count': yaml_improved,
                'yaml_improvement_rate': (yaml_improved / total * 100) if total > 0 else 0,
                'actionlint_improved_count': actionlint_improved,
                'actionlint_improvement_rate': (actionlint_improved / total * 100) if total > 0 else 0,
            },
            'similarity': {
                'avg_bleu': sum(valid_bleu) / len(valid_bleu) if valid_bleu else 0,
                'min_bleu': min(valid_bleu) if valid_bleu else 0,
                'max_bleu': max(valid_bleu) if valid_bleu else 0,
                'avg_edit_distance': sum(valid_edit) / len(valid_edit) if valid_edit else 0,
            }
        }
        
        # 2. actionlint í†µê³¼ íŒŒì¼ í†µê³„
        actionlint_passed = [r for r in results if r.get(f'{step_key}_actionlint_valid', False)]
        actionlint_count = len(actionlint_passed)
        
        if actionlint_count > 0:
            actionlint_bleu = [r['bleu_score'] for r in actionlint_passed if r['bleu_score'] >= 0]
            
            bleu_ranges = {
                '0.95-1.00': sum(1 for b in actionlint_bleu if 0.95 <= b <= 1.00),
                '0.90-0.95': sum(1 for b in actionlint_bleu if 0.90 <= b < 0.95),
                '0.85-0.90': sum(1 for b in actionlint_bleu if 0.85 <= b < 0.90),
                '0.80-0.85': sum(1 for b in actionlint_bleu if 0.80 <= b < 0.85),
                '0.70-0.80': sum(1 for b in actionlint_bleu if 0.70 <= b < 0.80),
                '< 0.70': sum(1 for b in actionlint_bleu if b < 0.70),
            }
            
            actionlint_stats = {
                'count': actionlint_count,
                'percentage_of_all': (actionlint_count / total * 100) if total > 0 else 0,
                'avg_bleu': sum(actionlint_bleu) / len(actionlint_bleu) if actionlint_bleu else 0,
                'min_bleu': min(actionlint_bleu) if actionlint_bleu else 0,
                'max_bleu': max(actionlint_bleu) if actionlint_bleu else 0,
                'bleu_distribution': bleu_ranges
            }
        else:
            actionlint_stats = {
                'count': 0,
                'percentage_of_all': 0,
                'avg_bleu': 0,
                'min_bleu': 0,
                'max_bleu': 0,
                'bleu_distribution': {}
            }
        
        # 3. ê³ í’ˆì§ˆ íŒŒì¼ í†µê³„ (actionlint + BLEU >= 0.85)
        high_quality = [r for r in actionlint_passed if r['bleu_score'] >= 0.85]
        hq_count = len(high_quality)
        
        if hq_count > 0:
            hq_bleu = [r['bleu_score'] for r in high_quality if r['bleu_score'] >= 0]
            hq_edit = [r['edit_distance'] for r in high_quality if r['edit_distance'] >= 0]
            
            high_quality_stats = {
                'count': hq_count,
                'percentage_of_all': (hq_count / total * 100) if total > 0 else 0,
                'percentage_of_actionlint_passed': (hq_count / actionlint_count * 100) if actionlint_count > 0 else 0,
                'avg_bleu': sum(hq_bleu) / len(hq_bleu) if hq_bleu else 0,
                'min_bleu': min(hq_bleu) if hq_bleu else 0,
                'max_bleu': max(hq_bleu) if hq_bleu else 0,
                'avg_edit_distance': sum(hq_edit) / len(hq_edit) if hq_edit else 0,
                'min_edit_distance': min(hq_edit) if hq_edit else 0,
                'max_edit_distance': max(hq_edit) if hq_edit else 0,
            }
        else:
            high_quality_stats = {
                'count': 0,
                'percentage_of_all': 0,
                'percentage_of_actionlint_passed': 0,
                'avg_bleu': 0,
                'min_bleu': 0,
                'max_bleu': 0,
                'avg_edit_distance': 0,
                'min_edit_distance': 0,
                'max_edit_distance': 0,
            }
        
        return {
            'overall': overall_stats,
            'actionlint_passed': actionlint_stats,
            'high_quality': high_quality_stats
        }
    
    def _calculate_overall_stats(self, results: List[Dict], total: int) -> Dict:
        """ì „ì²´ íŒŒì¼ í†µê³„ ê³„ì‚°"""
        step1_yaml_success = sum(1 for r in results if r['step1_yaml_valid'])
        step1_actionlint_success = sum(1 for r in results if r['step1_actionlint_valid'])
        
        step2_yaml_success = sum(1 for r in results if r['step2_yaml_valid'])
        step2_actionlint_success = sum(1 for r in results if r['step2_actionlint_valid'])
        
        yaml_improved = sum(1 for r in results if r['yaml_improved'])
        actionlint_improved = sum(1 for r in results if r['actionlint_improved'])
        
        valid_bleu = [r['bleu_score'] for r in results if r['bleu_score'] >= 0]
        valid_edit = [r['edit_distance'] for r in results if r['edit_distance'] >= 0]
        
        return {
            'total_files': total,
            'step1': {
                'yaml_success': step1_yaml_success,
                'yaml_success_rate': (step1_yaml_success / total * 100) if total > 0 else 0,
                'actionlint_success': step1_actionlint_success,
                'actionlint_success_rate': (step1_actionlint_success / total * 100) if total > 0 else 0,
            },
            'step2': {
                'yaml_success': step2_yaml_success,
                'yaml_success_rate': (step2_yaml_success / total * 100) if total > 0 else 0,
                'actionlint_success': step2_actionlint_success,
                'actionlint_success_rate': (step2_actionlint_success / total * 100) if total > 0 else 0,
            },
            'improvement': {
                'yaml_improved_count': yaml_improved,
                'yaml_improvement_rate': (yaml_improved / total * 100) if total > 0 else 0,
                'actionlint_improved_count': actionlint_improved,
                'actionlint_improvement_rate': (actionlint_improved / total * 100) if total > 0 else 0,
            },
            'similarity': {
                'avg_bleu': sum(valid_bleu) / len(valid_bleu) if valid_bleu else 0,
                'min_bleu': min(valid_bleu) if valid_bleu else 0,
                'max_bleu': max(valid_bleu) if valid_bleu else 0,
                'avg_edit_distance': sum(valid_edit) / len(valid_edit) if valid_edit else 0,
            }
        }
    
    def _calculate_actionlint_passed_stats(self, results: List[Dict], total: int) -> Dict:
        """actionlint í†µê³¼ íŒŒì¼ë§Œì˜ í†µê³„"""
        if total == 0:
            return {
                'count': 0,
                'percentage_of_all': 0,
                'avg_bleu': 0,
                'min_bleu': 0,
                'max_bleu': 0,
                'bleu_distribution': {}
            }
        
        valid_bleu = [r['bleu_score'] for r in results if r['bleu_score'] >= 0]
        
        # BLEU ë¶„í¬ ê³„ì‚°
        bleu_ranges = {
            '0.95-1.00': sum(1 for b in valid_bleu if 0.95 <= b <= 1.00),
            '0.90-0.95': sum(1 for b in valid_bleu if 0.90 <= b < 0.95),
            '0.85-0.90': sum(1 for b in valid_bleu if 0.85 <= b < 0.90),
            '0.80-0.85': sum(1 for b in valid_bleu if 0.80 <= b < 0.85),
            '0.70-0.80': sum(1 for b in valid_bleu if 0.70 <= b < 0.80),
            '< 0.70': sum(1 for b in valid_bleu if b < 0.70),
        }
        
        return {
            'count': total,
            'percentage_of_all': 0,  # ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨ì€ ë‚˜ì¤‘ì— ê³„ì‚°
            'avg_bleu': sum(valid_bleu) / len(valid_bleu) if valid_bleu else 0,
            'min_bleu': min(valid_bleu) if valid_bleu else 0,
            'max_bleu': max(valid_bleu) if valid_bleu else 0,
            'bleu_distribution': bleu_ranges
        }
    
    def _calculate_high_quality_stats(self, results: List[Dict], total: int) -> Dict:
        """actionlint í†µê³¼ + BLEU >= 0.85 íŒŒì¼ í†µê³„"""
        if total == 0:
            return {
                'count': 0,
                'percentage_of_all': 0,
                'percentage_of_actionlint_passed': 0,
                'avg_bleu': 0,
                'min_bleu': 0,
                'max_bleu': 0,
            }
        
        valid_bleu = [r['bleu_score'] for r in results if r['bleu_score'] >= 0]
        
        return {
            'count': total,
            'percentage_of_all': 0,  # ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨ì€ ë‚˜ì¤‘ì— ê³„ì‚°
            'percentage_of_actionlint_passed': 0,  # actionlint í†µê³¼ ëŒ€ë¹„ ë¹„ìœ¨ì€ ë‚˜ì¤‘ì— ê³„ì‚°
            'avg_bleu': sum(valid_bleu) / len(valid_bleu) if valid_bleu else 0,
            'min_bleu': min(valid_bleu) if valid_bleu else 0,
            'max_bleu': max(valid_bleu) if valid_bleu else 0,
        }
    
    def save_comparison_results(self, summary: Dict):
        """ë¹„êµ ê²°ê³¼ë¥¼ JSONê³¼ CSVë¡œ ì €ì¥ (stepë³„ë¡œ)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ì €ì¥ (ì „ì²´)
        json_file = self.output_dir / f"all_workflows_comparison_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"JSON ê²°ê³¼ ì €ì¥: {json_file}")
        
        # ê° stepë³„ë¡œ CSV ì €ì¥
        for step_key in ['step2', 'step3', 'step4', 'step5']:
            step_data = summary['step_results'].get(step_key, {})
            
            if not step_data or step_data.get('file_pairs_count', 0) == 0:
                self.logger.info(f"{step_key}: ë°ì´í„° ì—†ìŒ, CSV ìƒì„± ê±´ë„ˆëœ€")
                continue
            
            results = step_data.get('results', [])
            stats = step_data.get('stats', {})
            
            # ìƒì„¸ ê²°ê³¼ CSV
            csv_file = self.output_dir / f"{step_key}_comparison_{timestamp}.csv"
            
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                
                # í—¤ë”
                writer.writerow([
                    'base_name', 'step1_file', f'{step_key}_file',
                    'step1_yaml_valid', 'step1_actionlint_valid',
                    'step1_syntax_errors', 'step1_expression_errors',
                    f'{step_key}_yaml_valid', f'{step_key}_actionlint_valid',
                    f'{step_key}_syntax_errors', f'{step_key}_expression_errors',
                    'yaml_improved', 'actionlint_improved',
                    'edit_distance', 'bleu_score',
                    'is_actionlint_passed', 'is_high_quality'
                ])
                
                # ë°ì´í„°
                for r in results:
                    is_actionlint_passed = r.get(f'{step_key}_actionlint_valid', False)
                    is_high_quality = is_actionlint_passed and r['bleu_score'] >= 0.85
                    
                    writer.writerow([
                        r['base_name'],
                        r['step1_file'],
                        r.get(f'{step_key}_file', ''),
                        r['step1_yaml_valid'],
                        r['step1_actionlint_valid'],
                        r['step1_syntax_error_count'],
                        r['step1_expression_error_count'],
                        r.get(f'{step_key}_yaml_valid', False),
                        r.get(f'{step_key}_actionlint_valid', False),
                        r.get(f'{step_key}_syntax_error_count', 0),
                        r.get(f'{step_key}_expression_error_count', 0),
                        r['yaml_improved'],
                        r['actionlint_improved'],
                        r['edit_distance'],
                        f"{r['bleu_score']:.4f}" if r['bleu_score'] >= 0 else "N/A",
                        is_actionlint_passed,
                        is_high_quality
                    ])
            
            self.logger.info(f"{step_key} CSV ìƒì„¸ ê²°ê³¼ ì €ì¥: {csv_file}")
            
            # í†µê³„ ìš”ì•½ CSV
            if stats:
                stats_csv = self.output_dir / f"{step_key}_stats_{timestamp}.csv"
                with open(stats_csv, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(['Category', 'Metric', 'Value'])
                    
                    overall = stats.get('overall', {})
                    actionlint = stats.get('actionlint_passed', {})
                    hq = stats.get('high_quality', {})
                    
                    # ì „ì²´ í†µê³„
                    if overall:
                        writer.writerow(['Overall', 'Total Files', overall.get('total_files', 0)])
                        stepN_data = overall.get(step_key, {})
                        writer.writerow(['Overall', f'{step_key.upper()} YAML Success Rate', 
                                       f"{stepN_data.get('yaml_success_rate', 0):.2f}%"])
                        writer.writerow(['Overall', f'{step_key.upper()} actionlint Success Rate', 
                                       f"{stepN_data.get('actionlint_success_rate', 0):.2f}%"])
                        similarity = overall.get('similarity', {})
                        writer.writerow(['Overall', 'Average BLEU Score', 
                                       f"{similarity.get('avg_bleu', 0):.4f}"])
                    
                    # actionlint í†µê³¼ íŒŒì¼
                    if actionlint:
                        writer.writerow(['Actionlint Passed', 'Count', actionlint.get('count', 0)])
                        writer.writerow(['Actionlint Passed', 'Percentage of All', 
                                       f"{actionlint.get('percentage_of_all', 0):.2f}%"])
                        writer.writerow(['Actionlint Passed', 'Average BLEU', 
                                       f"{actionlint.get('avg_bleu', 0):.4f}"])
                    
                    # ê³ í’ˆì§ˆ íŒŒì¼
                    if hq:
                        writer.writerow(['High Quality (actionlint + BLEU>=0.85)', 'Count', hq.get('count', 0)])
                        writer.writerow(['High Quality', 'Percentage of All', 
                                       f"{hq.get('percentage_of_all', 0):.2f}%"])
                        writer.writerow(['High Quality', 'Percentage of Actionlint Passed', 
                                       f"{hq.get('percentage_of_actionlint_passed', 0):.2f}%"])
                        writer.writerow(['High Quality', 'Average BLEU', 
                                       f"{hq.get('avg_bleu', 0):.4f}"])
                        writer.writerow(['High Quality', 'Average Edit Distance', 
                                       f"{hq.get('avg_edit_distance', 0):.2f}"])
                        writer.writerow(['High Quality', 'Edit Distance Range', 
                                       f"{hq.get('min_edit_distance', 0):.0f} ~ {hq.get('max_edit_distance', 0):.0f}"])
                
                self.logger.info(f"{step_key} CSV í†µê³„ ìš”ì•½ ì €ì¥: {stats_csv}")
            
            # ê³ í’ˆì§ˆ íŒŒì¼ ëª©ë¡ CSV ì €ì¥
            high_quality_files = [r for r in results 
                                 if r.get(f'{step_key}_actionlint_valid', False) 
                                 and r['bleu_score'] >= 0.85]
            
            if high_quality_files:
                hq_csv = self.output_dir / f"{step_key}_high_quality_files_{timestamp}.csv"
                with open(hq_csv, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    
                    # í—¤ë”
                    writer.writerow([
                        'base_name', 'step1_file', f'{step_key}_file',
                        'bleu_score', 'edit_distance',
                        'step1_syntax_errors', 'step1_expression_errors',
                        f'{step_key}_syntax_errors', f'{step_key}_expression_errors',
                        'yaml_improved', 'actionlint_improved'
                    ])
                    
                    # ë°ì´í„° (BLEU ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬)
                    sorted_files = sorted(high_quality_files, key=lambda x: x['bleu_score'], reverse=True)
                    
                    for r in sorted_files:
                        writer.writerow([
                            r['base_name'],
                            r['step1_file'],
                            r.get(f'{step_key}_file', ''),
                            f"{r['bleu_score']:.4f}",
                            r['edit_distance'],
                            r['step1_syntax_error_count'],
                            r['step1_expression_error_count'],
                            r.get(f'{step_key}_syntax_error_count', 0),
                            r.get(f'{step_key}_expression_error_count', 0),
                            r['yaml_improved'],
                            r['actionlint_improved']
                        ])
                
                self.logger.info(f"{step_key} ê³ í’ˆì§ˆ íŒŒì¼ ëª©ë¡ ì €ì¥: {hq_csv} ({len(high_quality_files)}ê°œ)")
    
    def print_comparison_summary(self, summary: Dict):
        """ë¹„êµ ê²°ê³¼ ìš”ì•½ ì¶œë ¥ (stepë³„ë¡œ)"""
        print("\n" + "=" * 80)
        print("ì „ì²´ ì›Œí¬í”Œë¡œìš° ë¹„êµ í‰ê°€ ê²°ê³¼ (Stepë³„)")
        print("=" * 80)
        
        metadata = summary['metadata']
        if 'workflows_dir' in metadata:
            print(f"\nğŸ“ ë¶„ì„ ìœ„ì¹˜: {metadata['workflows_dir']}")
        elif 'step_dirs' in metadata:
            print(f"\nğŸ“ Step ë””ë ‰í† ë¦¬:")
            for step_name, step_path in metadata['step_dirs'].items():
                print(f"  {step_name}: {step_path}")
        
        print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {metadata['processing_time']:.2f}ì´ˆ")
        
        # ê° stepë³„ë¡œ ì¶œë ¥
        for step_key in ['step2', 'step3', 'step4', 'step5']:
            step_data = summary['step_results'].get(step_key, {})
            
            if not step_data or step_data.get('file_pairs_count', 0) == 0:
                print(f"\n{'='*80}")
                print(f"{step_key.upper()}: ë°ì´í„° ì—†ìŒ")
                print(f"{'='*80}")
                continue
            
            total = step_data['file_pairs_count']
            stats = step_data.get('stats', {})
            
            if not stats:
                continue
            
            overall = stats.get('overall', {})
            actionlint = stats.get('actionlint_passed', {})
            hq = stats.get('high_quality', {})
            
            print("\n" + "=" * 80)
            print(f"ğŸ“Š {step_key.upper()} ë¹„êµ ê²°ê³¼")
            print("=" * 80)
            print(f"ì´ íŒŒì¼ ìŒ: {total}")
            
            # 1. ì „ì²´ íŒŒì¼ í†µê³„
            if overall:
                print(f"\n1ï¸âƒ£  ì „ì²´ íŒŒì¼ í†µê³„")
                print("-" * 80)
                
                stepN_data = overall.get(step_key, {})
                print(f"\n{step_key.upper()} ì„±ê³µë¥ :")
                print(f"  YAML íŒŒì‹±: {stepN_data.get('yaml_success', 0)}/{total} "
                      f"({stepN_data.get('yaml_success_rate', 0):.2f}%)")
                print(f"  actionlint: {stepN_data.get('actionlint_success', 0)}/{total} "
                      f"({stepN_data.get('actionlint_success_rate', 0):.2f}%)")
                
                improvement = overall.get('improvement', {})
                print(f"\nê°œì„ ìœ¨:")
                print(f"  YAML ê°œì„ : {improvement.get('yaml_improved_count', 0)}ê°œ íŒŒì¼ "
                      f"({improvement.get('yaml_improvement_rate', 0):.2f}%)")
                print(f"  actionlint ê°œì„ : {improvement.get('actionlint_improved_count', 0)}ê°œ íŒŒì¼ "
                      f"({improvement.get('actionlint_improvement_rate', 0):.2f}%)")
                
                similarity = overall.get('similarity', {})
                print(f"\nìœ ì‚¬ë„:")
                print(f"  í‰ê·  BLEU: {similarity.get('avg_bleu', 0):.4f}")
                print(f"  BLEU ë²”ìœ„: {similarity.get('min_bleu', 0):.4f} ~ "
                      f"{similarity.get('max_bleu', 0):.4f}")
                print(f"  í‰ê·  Edit Distance: {similarity.get('avg_edit_distance', 0):.1f}")
            
            # 2. actionlint í†µê³¼ íŒŒì¼ í†µê³„
            if actionlint and actionlint.get('count', 0) > 0:
                print(f"\n2ï¸âƒ£  actionlint í†µê³¼ íŒŒì¼ í†µê³„")
                print("-" * 80)
                
                print(f"\ní†µê³¼í•œ íŒŒì¼ ìˆ˜: {actionlint['count']}/{total} "
                      f"({actionlint.get('percentage_of_all', 0):.2f}%)")
                print(f"í‰ê·  BLEU: {actionlint.get('avg_bleu', 0):.4f}")
                print(f"BLEU ë²”ìœ„: {actionlint.get('min_bleu', 0):.4f} ~ "
                      f"{actionlint.get('max_bleu', 0):.4f}")
                
                bleu_dist = actionlint.get('bleu_distribution', {})
                if bleu_dist:
                    print(f"\nBLEU ë¶„í¬:")
                    for range_name, count in bleu_dist.items():
                        percentage = (count / actionlint['count'] * 100) if actionlint['count'] > 0 else 0
                        print(f"  {range_name}: {count}ê°œ ({percentage:.1f}%)")
            
            # 3. ê³ í’ˆì§ˆ íŒŒì¼ í†µê³„
            if hq and hq.get('count', 0) > 0:
                print(f"\n3ï¸âƒ£  ê³ í’ˆì§ˆ íŒŒì¼ í†µê³„ (actionlint í†µê³¼ + BLEU >= 0.85)")
                print("-" * 80)
                
                print(f"\nê³ í’ˆì§ˆ íŒŒì¼ ìˆ˜: {hq['count']}/{total} "
                      f"({hq.get('percentage_of_all', 0):.2f}%)")
                if actionlint.get('count', 0) > 0:
                    print(f"actionlint í†µê³¼ íŒŒì¼ ì¤‘: {hq['count']}/{actionlint['count']} "
                          f"({hq.get('percentage_of_actionlint_passed', 0):.2f}%)")
                print(f"í‰ê·  BLEU: {hq.get('avg_bleu', 0):.4f}")
                print(f"BLEU ë²”ìœ„: {hq.get('min_bleu', 0):.4f} ~ {hq.get('max_bleu', 0):.4f}")
                print(f"í‰ê·  Edit Distance: {hq.get('avg_edit_distance', 0):.2f}")
                print(f"Edit Distance ë²”ìœ„: {hq.get('min_edit_distance', 0):.0f} ~ {hq.get('max_edit_distance', 0):.0f}")
        
        print("\n" + "=" * 80)
        print("ğŸ‰ ë¹„êµ í‰ê°€ ì™„ë£Œ!")
        print("=" * 80)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì „ì²´ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ë¹„êµ í‰ê°€ ë„êµ¬")
    
    parser.add_argument("--step1-dir", default="/Users/nam/step1", 
                       help="Step1 íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: /Users/nam/step1)")
    parser.add_argument("--step2-dir", default="/Users/nam/step2", 
                       help="Step2 íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: /Users/nam/step2)")
    parser.add_argument("--step3-dir", default="/Users/nam/step3", 
                       help="Step3 íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: /Users/nam/step3)")
    parser.add_argument("--step4-dir", default="/Users/nam/step4", 
                       help="Step4 íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: /Users/nam/step4)")
    parser.add_argument("--step5-dir", default="/Users/nam/step5", 
                       help="Step5 íŒŒì¼ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: /Users/nam/step5)")
    parser.add_argument("--max-files", type=int, 
                       help="í‰ê°€í•  ìµœëŒ€ íŒŒì¼ ìˆ˜")
    parser.add_argument("--csv-file", default="/Users/nam/Desktop/repository/Catching-Smells/data/all_steps.csv",
                       help="Step ë§¤í•‘ CSV íŒŒì¼ (ê¸°ë³¸: all_steps.csv)")
    parser.add_argument("--output-dir", default="./evaluation/all_workflows_comparison",
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ./evaluation/all_workflows_comparison)")
    parser.add_argument("--log-level", default="INFO", 
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"])
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=getattr(logging, args.log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        comparator = AllWorkflowsComparator(args.output_dir)
        
        step_dirs = {
            'step1': args.step1_dir,
            'step2': args.step2_dir,
            'step3': args.step3_dir,
            'step4': args.step4_dir,
            'step5': args.step5_dir,
        }
        
        summary = comparator.compare_all_workflows_by_dirs(
            step_dirs,
            csv_file=args.csv_file,
            max_files=args.max_files
        )
        
        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {args.output_dir}")
        
    except Exception as e:
        logging.error(f"ë¹„êµ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
